{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Modeling -  selection of the best tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Purpose of the action </b> - checking accuracy of prediction on test set using different types of tree-based models:\n",
    "- RandomForestClassifier\n",
    "- AdaBoostClassifier\n",
    "- XGBClassifier\n",
    "- CatBoostClassifier\n",
    "\n",
    "<b> </b>\n",
    "<b> Action plan </b>:\n",
    "- Test 20 diffrent models for each type\n",
    "- Use ParameterSampler to generate different models with random hyperparameters\n",
    "- Use training set for fitting model and use validation set for model evaluation \n",
    "- Select the best 5 models of each type and create one averaging model (Votingclassifier)\n",
    "- Create one large averaging model using the best one model of each type\n",
    "- Create another large averaging model from the previously created VotingClassifiers (each model contains the top 5 models of the same type)\n",
    "- Save this models for use in future\n",
    "- Compare prediction accuracy and other metrics on test set and save results for future purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Import nessesary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import pickle\n",
    "from modeling import make_voting_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Create empty lists for future results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = []\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "roc_auc_score = []\n",
    "models_name = []\n",
    "single_models = []\n",
    "voting_models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Perform ensembling for RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_randomforest.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_randomforest.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_test_set_randomforest.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Split datasets to feature and label sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier{'random_state': 1, 'n_estimators': 1200, 'max_depth': 15}\n",
      "Accuracy score on training set: 0.9988 | Accuracy score on validation set: 0.7091\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 1, 'n_estimators': 800, 'max_depth': 9}\n",
      "Accuracy score on training set: 0.8478 | Accuracy score on validation set: 0.6909\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 6, 'n_estimators': 600, 'max_depth': 19}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.703\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 2, 'n_estimators': 1000, 'max_depth': 15}\n",
      "Accuracy score on training set: 0.9988 | Accuracy score on validation set: 0.703\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 8, 'n_estimators': 1200, 'max_depth': 17}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.6909\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 5, 'n_estimators': 600, 'max_depth': 17}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.6848\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 8, 'n_estimators': 600, 'max_depth': 13}\n",
      "Accuracy score on training set: 0.9847 | Accuracy score on validation set: 0.697\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 5, 'n_estimators': 800, 'max_depth': 9}\n",
      "Accuracy score on training set: 0.8488 | Accuracy score on validation set: 0.697\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 9, 'n_estimators': 1200, 'max_depth': 21}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.703\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 9, 'n_estimators': 600, 'max_depth': 21}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.697\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 7, 'n_estimators': 400, 'max_depth': 15}\n",
      "Accuracy score on training set: 0.9988 | Accuracy score on validation set: 0.697\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 9, 'n_estimators': 600, 'max_depth': 9}\n",
      "Accuracy score on training set: 0.8488 | Accuracy score on validation set: 0.6909\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 9, 'n_estimators': 1200, 'max_depth': 13}\n",
      "Accuracy score on training set: 0.9854 | Accuracy score on validation set: 0.697\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 1, 'n_estimators': 600, 'max_depth': 21}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.703\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 1, 'n_estimators': 600, 'max_depth': 19}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.703\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 10, 'n_estimators': 600, 'max_depth': 9}\n",
      "Accuracy score on training set: 0.8487 | Accuracy score on validation set: 0.6939\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 5, 'n_estimators': 1200, 'max_depth': 21}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.703\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 6, 'n_estimators': 800, 'max_depth': 13}\n",
      "Accuracy score on training set: 0.9842 | Accuracy score on validation set: 0.703\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 7, 'n_estimators': 600, 'max_depth': 9}\n",
      "Accuracy score on training set: 0.8493 | Accuracy score on validation set: 0.703\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier{'random_state': 0, 'n_estimators': 1200, 'max_depth': 11}\n",
      "Accuracy score on training set: 0.9424 | Accuracy score on validation set: 0.7061\n",
      "--------------------------------------------------------------------------------\n",
      "[\"RandomForestClassifier{'random_state': 1, 'n_estimators': 1200, 'max_depth': 15}\"\n",
      " \"RandomForestClassifier{'random_state': 0, 'n_estimators': 1200, 'max_depth': 11}\"\n",
      " \"RandomForestClassifier{'random_state': 6, 'n_estimators': 800, 'max_depth': 13}\"\n",
      " \"RandomForestClassifier{'random_state': 7, 'n_estimators': 600, 'max_depth': 9}\"\n",
      " \"RandomForestClassifier{'random_state': 6, 'n_estimators': 600, 'max_depth': 19}\"]\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid={\n",
    "   'n_estimators': [400, 600, 800, 1000, 1200],\n",
    "   'max_depth': [7, 9, 11, 13, 15, 17, 19, 21],\n",
    "   'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10] \n",
    "}\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=RandomForestClassifier, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=15, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1200,\n",
       "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.5 Fit averaging model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Voting_RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# train averaging model on training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'{clf.__class__.__name__}'\n",
    "voting_clf_name = f'Voting_{voting_clf.estimators_[0].__class__.__name__}'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Perform ensembling for AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_adaboost.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_adaboost.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_test_set_adaboost.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier{'random_state': 2, 'n_estimators': 90, 'learning_rate': 1.4, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.7441 | Accuracy score on validation set: 0.6848\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 7, 'n_estimators': 80, 'learning_rate': 1.4, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.8064 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 8, 'n_estimators': 90, 'learning_rate': 1.0, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.8185 | Accuracy score on validation set: 0.6606\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 6, 'n_estimators': 50, 'learning_rate': 1.0, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.7714 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 10, 'n_estimators': 70, 'learning_rate': 1.2, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.8847 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 2, 'n_estimators': 80, 'learning_rate': 1.4, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.9978 | Accuracy score on validation set: 0.6485\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 4, 'n_estimators': 40, 'learning_rate': 0.6, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.7108 | Accuracy score on validation set: 0.7212\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 6, 'n_estimators': 20, 'learning_rate': 1.4, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.7276 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 0, 'n_estimators': 90, 'learning_rate': 1.2, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=1, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.7032 | Accuracy score on validation set: 0.703\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 8, 'n_estimators': 90, 'learning_rate': 0.8, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.9059 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 1, 'n_estimators': 40, 'learning_rate': 1.4, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.9093 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 9, 'n_estimators': 50, 'learning_rate': 0.8, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=1, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.6968 | Accuracy score on validation set: 0.6848\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier{'random_state': 2, 'n_estimators': 30, 'learning_rate': 1.4, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.7877 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 10, 'n_estimators': 80, 'learning_rate': 1.2, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.7392 | Accuracy score on validation set: 0.697\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 8, 'n_estimators': 30, 'learning_rate': 1.0, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.7943 | Accuracy score on validation set: 0.6485\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 5, 'n_estimators': 90, 'learning_rate': 1.2, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.8263 | Accuracy score on validation set: 0.6909\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 9, 'n_estimators': 90, 'learning_rate': 0.6, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.8042 | Accuracy score on validation set: 0.6818\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 7, 'n_estimators': 50, 'learning_rate': 1.2, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.7675 | Accuracy score on validation set: 0.6788\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 8, 'n_estimators': 30, 'learning_rate': 0.6, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.7012 | Accuracy score on validation set: 0.7333\n",
      "--------------------------------------------------------------------------------\n",
      "AdaBoostClassifier{'random_state': 10, 'n_estimators': 30, 'learning_rate': 0.6, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=1, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "Accuracy score on training set: 0.6879 | Accuracy score on validation set: 0.697\n",
      "--------------------------------------------------------------------------------\n",
      "[\"AdaBoostClassifier{'random_state': 8, 'n_estimators': 30, 'learning_rate': 0.6, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\\n                       max_depth=2, max_features=None, max_leaf_nodes=None,\\n                       min_impurity_decrease=0.0, min_impurity_split=None,\\n                       min_samples_leaf=1, min_samples_split=2,\\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\\n                       random_state=None, splitter='best')}\"\n",
      " \"AdaBoostClassifier{'random_state': 4, 'n_estimators': 40, 'learning_rate': 0.6, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\\n                       max_depth=2, max_features=None, max_leaf_nodes=None,\\n                       min_impurity_decrease=0.0, min_impurity_split=None,\\n                       min_samples_leaf=1, min_samples_split=2,\\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\\n                       random_state=None, splitter='best')}\"\n",
      " \"AdaBoostClassifier{'random_state': 0, 'n_estimators': 90, 'learning_rate': 1.2, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\\n                       max_depth=1, max_features=None, max_leaf_nodes=None,\\n                       min_impurity_decrease=0.0, min_impurity_split=None,\\n                       min_samples_leaf=1, min_samples_split=2,\\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\\n                       random_state=None, splitter='best')}\"\n",
      " \"AdaBoostClassifier{'random_state': 10, 'n_estimators': 30, 'learning_rate': 0.6, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\\n                       max_depth=1, max_features=None, max_leaf_nodes=None,\\n                       min_impurity_decrease=0.0, min_impurity_split=None,\\n                       min_samples_leaf=1, min_samples_split=2,\\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\\n                       random_state=None, splitter='best')}\"\n",
      " \"AdaBoostClassifier{'random_state': 10, 'n_estimators': 80, 'learning_rate': 1.2, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\\n                       max_depth=2, max_features=None, max_leaf_nodes=None,\\n                       min_impurity_decrease=0.0, min_impurity_split=None,\\n                       min_samples_leaf=1, min_samples_split=2,\\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\\n                       random_state=None, splitter='best')}\"]\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid={\n",
    "   'base_estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), \n",
    "                      DecisionTreeClassifier(max_depth=3), DecisionTreeClassifier(max_depth=4),\n",
    "                      DecisionTreeClassifier(max_depth=5)], \n",
    "   'n_estimators': [20, 30, 40, 50, 70, 80, 90, 100],\n",
    "   'learning_rate': [0.6, 0.8, 1.0, 1.2, 1.4],\n",
    "   'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10] \n",
    "}\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=AdaBoostClassifier, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                         class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=2,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort='deprecated',\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.6, n_estimators=30, random_state=8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.5 Fit averaging model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Voting_RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# train averaging model on training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'{clf.__class__.__name__}'\n",
    "voting_clf_name = f'Voting_{voting_clf.estimators_[0].__class__.__name__}'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Perform ensembling for XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_xgbboost.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_xgbboost.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_test_set_xgbboost.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier{'subsample': 0.9, 'scale_pos_weight': 1.2, 'reg_alpha': 1e-06, 'random_state': 6, 'n_estimators': 300, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
      "Accuracy score on training set: 0.8239 | Accuracy score on validation set: 0.7091\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.8, 'scale_pos_weight': 1.2, 'reg_alpha': 1e-05, 'random_state': 8, 'n_estimators': 700, 'min_child_weight': 3, 'max_depth': 3, 'learning_rate': 0.01, 'gamma': 0.6, 'colsample_bytree': 0.9}\n",
      "Accuracy score on training set: 0.7303 | Accuracy score on validation set: 0.7061\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.8, 'scale_pos_weight': 0.8, 'reg_alpha': 1e-05, 'random_state': 2, 'n_estimators': 700, 'min_child_weight': 3, 'max_depth': 8, 'learning_rate': 0.01, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
      "Accuracy score on training set: 0.9567 | Accuracy score on validation set: 0.7061\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.7, 'scale_pos_weight': 1.2, 'reg_alpha': 1e-05, 'random_state': 8, 'n_estimators': 400, 'min_child_weight': 2, 'max_depth': 7, 'learning_rate': 0.01, 'gamma': 0.4, 'colsample_bytree': 0.8}\n",
      "Accuracy score on training set: 0.8931 | Accuracy score on validation set: 0.7091\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.9, 'scale_pos_weight': 1, 'reg_alpha': 0.0001, 'random_state': 7, 'n_estimators': 500, 'min_child_weight': 2, 'max_depth': 7, 'learning_rate': 0.005, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Accuracy score on training set: 0.8774 | Accuracy score on validation set: 0.7091\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.8, 'scale_pos_weight': 0.8, 'reg_alpha': 0.0001, 'random_state': 10, 'n_estimators': 600, 'min_child_weight': 3, 'max_depth': 3, 'learning_rate': 0.005, 'gamma': 0.6, 'colsample_bytree': 0.9}\n",
      "Accuracy score on training set: 0.701 | Accuracy score on validation set: 0.6848\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.7, 'scale_pos_weight': 0.8, 'reg_alpha': 0.0001, 'random_state': 3, 'n_estimators': 400, 'min_child_weight': 4, 'max_depth': 3, 'learning_rate': 0.01, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
      "Accuracy score on training set: 0.7089 | Accuracy score on validation set: 0.6939\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.8, 'scale_pos_weight': 1, 'reg_alpha': 1e-06, 'random_state': 8, 'n_estimators': 700, 'min_child_weight': 2, 'max_depth': 3, 'learning_rate': 0.02, 'gamma': 0.2, 'colsample_bytree': 0.7}\n",
      "Accuracy score on training set: 0.7662 | Accuracy score on validation set: 0.7091\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.7, 'scale_pos_weight': 1.2, 'reg_alpha': 1e-05, 'random_state': 4, 'n_estimators': 500, 'min_child_weight': 4, 'max_depth': 3, 'learning_rate': 0.02, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
      "Accuracy score on training set: 0.7419 | Accuracy score on validation set: 0.7212\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.7, 'scale_pos_weight': 1.2, 'reg_alpha': 0.0001, 'random_state': 7, 'n_estimators': 300, 'min_child_weight': 2, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.9}\n",
      "Accuracy score on training set: 0.82 | Accuracy score on validation set: 0.7091\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.7, 'scale_pos_weight': 0.8, 'reg_alpha': 1e-06, 'random_state': 6, 'n_estimators': 700, 'min_child_weight': 3, 'max_depth': 4, 'learning_rate': 0.005, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
      "Accuracy score on training set: 0.7303 | Accuracy score on validation set: 0.6939\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.7, 'scale_pos_weight': 0.8, 'reg_alpha': 0.0001, 'random_state': 10, 'n_estimators': 700, 'min_child_weight': 2, 'max_depth': 6, 'learning_rate': 0.005, 'gamma': 0.6, 'colsample_bytree': 0.7}\n",
      "Accuracy score on training set: 0.8185 | Accuracy score on validation set: 0.6909\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.8, 'scale_pos_weight': 1, 'reg_alpha': 1e-05, 'random_state': 2, 'n_estimators': 700, 'min_child_weight': 4, 'max_depth': 3, 'learning_rate': 0.01, 'gamma': 0.6, 'colsample_bytree': 0.7}\n",
      "Accuracy score on training set: 0.7316 | Accuracy score on validation set: 0.7152\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.8, 'scale_pos_weight': 1, 'reg_alpha': 1e-05, 'random_state': 6, 'n_estimators': 400, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Accuracy score on training set: 0.787 | Accuracy score on validation set: 0.7091\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.9, 'scale_pos_weight': 1, 'reg_alpha': 1e-06, 'random_state': 3, 'n_estimators': 600, 'min_child_weight': 2, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.7}\n",
      "Accuracy score on training set: 0.8806 | Accuracy score on validation set: 0.7121\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.8, 'scale_pos_weight': 0.8, 'reg_alpha': 1e-06, 'random_state': 10, 'n_estimators': 600, 'min_child_weight': 4, 'max_depth': 4, 'learning_rate': 0.005, 'gamma': 0.4, 'colsample_bytree': 0.8}\n",
      "Accuracy score on training set: 0.7271 | Accuracy score on validation set: 0.6879\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.9, 'scale_pos_weight': 0.8, 'reg_alpha': 1e-06, 'random_state': 2, 'n_estimators': 600, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.02, 'gamma': 0.2, 'colsample_bytree': 0.7}\n",
      "Accuracy score on training set: 0.8616 | Accuracy score on validation set: 0.7152\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.7, 'scale_pos_weight': 1, 'reg_alpha': 1e-05, 'random_state': 8, 'n_estimators': 600, 'min_child_weight': 2, 'max_depth': 3, 'learning_rate': 0.005, 'gamma': 0.4, 'colsample_bytree': 0.8}\n",
      "Accuracy score on training set: 0.7094 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.8, 'scale_pos_weight': 1.2, 'reg_alpha': 0.0001, 'random_state': 6, 'n_estimators': 600, 'min_child_weight': 2, 'max_depth': 8, 'learning_rate': 0.02, 'gamma': 0.6, 'colsample_bytree': 0.9}\n",
      "Accuracy score on training set: 0.9978 | Accuracy score on validation set: 0.7303\n",
      "--------------------------------------------------------------------------------\n",
      "XGBClassifier{'subsample': 0.7, 'scale_pos_weight': 0.8, 'reg_alpha': 1e-06, 'random_state': 2, 'n_estimators': 400, 'min_child_weight': 3, 'max_depth': 4, 'learning_rate': 0.005, 'gamma': 0.4, 'colsample_bytree': 0.8}\n",
      "Accuracy score on training set: 0.7114 | Accuracy score on validation set: 0.6879\n",
      "--------------------------------------------------------------------------------\n",
      "[\"XGBClassifier{'subsample': 0.8, 'scale_pos_weight': 1.2, 'reg_alpha': 0.0001, 'random_state': 6, 'n_estimators': 600, 'min_child_weight': 2, 'max_depth': 8, 'learning_rate': 0.02, 'gamma': 0.6, 'colsample_bytree': 0.9}\"\n",
      " \"XGBClassifier{'subsample': 0.7, 'scale_pos_weight': 1.2, 'reg_alpha': 1e-05, 'random_state': 4, 'n_estimators': 500, 'min_child_weight': 4, 'max_depth': 3, 'learning_rate': 0.02, 'gamma': 0.4, 'colsample_bytree': 0.7}\"\n",
      " \"XGBClassifier{'subsample': 0.9, 'scale_pos_weight': 0.8, 'reg_alpha': 1e-06, 'random_state': 2, 'n_estimators': 600, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.02, 'gamma': 0.2, 'colsample_bytree': 0.7}\"\n",
      " \"XGBClassifier{'subsample': 0.8, 'scale_pos_weight': 1, 'reg_alpha': 1e-05, 'random_state': 2, 'n_estimators': 700, 'min_child_weight': 4, 'max_depth': 3, 'learning_rate': 0.01, 'gamma': 0.6, 'colsample_bytree': 0.7}\"\n",
      " \"XGBClassifier{'subsample': 0.9, 'scale_pos_weight': 1, 'reg_alpha': 1e-06, 'random_state': 3, 'n_estimators': 600, 'min_child_weight': 2, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.7}\"]\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid = {\n",
    "                  'random_state':[0, 1, 2 ,3 ,4, 5, 6, 7, 8, 9, 10],\n",
    "                  'n_estimators': [300, 400, 500, 600, 700], \n",
    "                  'learning_rate' : [0.005, 0.01, 0.02],\n",
    "                  'max_depth' : [3, 4, 5, 6, 7, 8],\n",
    "                  'min_child_weight': [2, 3, 4],\n",
    "                  'gamma':[0.2, 0.4, 0.6],\n",
    "                  'subsample' : [0.7, 0.8, 0.9],\n",
    "                  'colsample_bytree' : [0.7, 0.8, 0.9],\n",
    "                  'scale_pos_weight' : [0.8, 1, 1.2],\n",
    "                  'reg_alpha':[1e-4, 1e-5, 1e-6]\n",
    "              }\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=XGBClassifier, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9, gamma=0.6,\n",
       "              learning_rate=0.02, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=2, missing=None, n_estimators=600, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=6,\n",
       "              reg_alpha=0.0001, reg_lambda=1, scale_pos_weight=1.2, seed=None,\n",
       "              silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.5 Fit averaging model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Voting_RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# train averaging model on training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'{clf.__class__.__name__}'\n",
    "voting_clf_name = f'Voting_{voting_clf.estimators_[0].__class__.__name__}'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Perform ensembling for CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_catboost.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_catboost.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_test_set_catboost.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 7, 'n_estimators': 500, 'max_depth': 5}\n",
      "Accuracy score on training set: 0.8286 | Accuracy score on validation set: 0.7182\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': 0.9, 'random_state': 5, 'n_estimators': 700, 'max_depth': 6}\n",
      "Accuracy score on training set: 0.8968 | Accuracy score on validation set: 0.7121\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 6, 'n_estimators': 400, 'max_depth': 6}\n",
      "Accuracy score on training set: 0.8806 | Accuracy score on validation set: 0.7242\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 10, 'n_estimators': 300, 'max_depth': 6}\n",
      "Accuracy score on training set: 0.8754 | Accuracy score on validation set: 0.7121\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': 0.8, 'random_state': 8, 'n_estimators': 700, 'max_depth': 7}\n",
      "Accuracy score on training set: 0.949 | Accuracy score on validation set: 0.7333\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': 0.9, 'random_state': 4, 'n_estimators': 500, 'max_depth': 9}\n",
      "Accuracy score on training set: 0.9993 | Accuracy score on validation set: 0.7091\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': 0.6, 'random_state': 5, 'n_estimators': 400, 'max_depth': 4}\n",
      "Accuracy score on training set: 0.7662 | Accuracy score on validation set: 0.7\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': 0.8, 'random_state': 5, 'n_estimators': 600, 'max_depth': 6}\n",
      "Accuracy score on training set: 0.8869 | Accuracy score on validation set: 0.7212\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 0, 'n_estimators': None, 'max_depth': 4}\n",
      "Accuracy score on training set: 0.78 | Accuracy score on validation set: 0.7091\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': 0.7, 'random_state': 10, 'n_estimators': 400, 'max_depth': 7}\n",
      "Accuracy score on training set: 0.9372 | Accuracy score on validation set: 0.7182\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 9, 'n_estimators': 400, 'max_depth': 9}\n",
      "Accuracy score on training set: 0.9988 | Accuracy score on validation set: 0.7061\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 4, 'n_estimators': 400, 'max_depth': None}\n",
      "Accuracy score on training set: 0.8865 | Accuracy score on validation set: 0.7212\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 7, 'n_estimators': None, 'max_depth': 8}\n",
      "Accuracy score on training set: 0.9899 | Accuracy score on validation set: 0.7303\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': 0.9, 'random_state': 10, 'n_estimators': 300, 'max_depth': 5}\n",
      "Accuracy score on training set: 0.8253 | Accuracy score on validation set: 0.7242\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': 0.6, 'random_state': 5, 'n_estimators': 300, 'max_depth': 10}\n",
      "Accuracy score on training set: 0.9998 | Accuracy score on validation set: 0.697\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 6, 'n_estimators': 500, 'max_depth': 7}\n",
      "Accuracy score on training set: 0.9433 | Accuracy score on validation set: 0.703\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': 0.8, 'random_state': 2, 'n_estimators': 400, 'max_depth': 10}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.7303\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 1, 'n_estimators': 600, 'max_depth': 6}\n",
      "Accuracy score on training set: 0.8897 | Accuracy score on validation set: 0.7212\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 4, 'n_estimators': 700, 'max_depth': 5}\n",
      "Accuracy score on training set: 0.8306 | Accuracy score on validation set: 0.7273\n",
      "--------------------------------------------------------------------------------\n",
      "CatBoostClassifier{'verbose': 0, 'subsample': 0.9, 'random_state': 2, 'n_estimators': None, 'max_depth': 10}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.7394\n",
      "--------------------------------------------------------------------------------\n",
      "[\"CatBoostClassifier{'verbose': 0, 'subsample': 0.9, 'random_state': 2, 'n_estimators': None, 'max_depth': 10}\"\n",
      " \"CatBoostClassifier{'verbose': 0, 'subsample': 0.8, 'random_state': 8, 'n_estimators': 700, 'max_depth': 7}\"\n",
      " \"CatBoostClassifier{'verbose': 0, 'subsample': 0.8, 'random_state': 2, 'n_estimators': 400, 'max_depth': 10}\"\n",
      " \"CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 7, 'n_estimators': None, 'max_depth': 8}\"\n",
      " \"CatBoostClassifier{'verbose': 0, 'subsample': None, 'random_state': 4, 'n_estimators': 700, 'max_depth': 5}\"]\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid = {\n",
    "                  'random_state':[0, 1, 2 ,3 ,4, 5, 6, 7, 8, 9, 10],\n",
    "                  'n_estimators': [None, 300, 400, 500, 600, 700], \n",
    "                  'max_depth' : [None, 4, 5, 6, 7, 8, 9, 10],\n",
    "                  'subsample' : [None, 0.6,0.7, 0.8, 0.9],\n",
    "                  'verbose': [0],\n",
    "              }\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=CatBoostClassifier, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x121c4727288>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.5 Fit averaging model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Voting_RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# train averaging model on training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'{clf.__class__.__name__}'\n",
    "voting_clf_name = f'Voting_{voting_clf.estimators_[0].__class__.__name__}'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Merge single and voting classifiers in largest models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.1 Import data dedicated for this models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_base_train_set.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_base_validation_set.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_base_test_set.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.3 Create new largest voting models and fit them on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TreeModelsVotingClassifier TreeModelsAveragingVotingClassifier\n"
     ]
    }
   ],
   "source": [
    "# create models\n",
    "\n",
    "# as base models using single classifier\n",
    "voting_tree_clf = VotingClassifier(estimators=single_models, voting='soft')\n",
    "# as base models using voting classifier\n",
    "average_voting_tree_clf = VotingClassifier(estimators=voting_models, voting='soft')\n",
    "\n",
    "# train models on all data\n",
    "voting_tree_clf.fit(X_train, y_train)\n",
    "average_voting_tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# give models a name\n",
    "voting_tree_clf_name = 'TreeModelsVotingClassifier'\n",
    "average_voting_tree_clf_name = 'TreeModelsAveragingVotingClassifier'\n",
    "print(voting_tree_clf_name, average_voting_tree_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.4 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single voting classifier to the lists\n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_tree_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_tree_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_tree_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_tree_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_tree_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for averaging voting classifier to the lists \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , average_voting_tree_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , average_voting_tree_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , average_voting_tree_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , average_voting_tree_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , average_voting_tree_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(voting_tree_clf_name)\n",
    "models_name.append(average_voting_tree_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.5 Save models for future purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save single voting model using pickle library\n",
    "with open(f'./models_new/{voting_tree_clf_name}.pickle', 'wb') as f:\n",
    "    # pickle the 'models'using the highest protocol available.\n",
    "    pickle.dump(voting_tree_clf, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# save averaging voting model using pickle library\n",
    "with open(f'./models_new/{average_voting_tree_clf_name}.pickle', 'wb') as f:\n",
    "    # pickle the 'models'using the highest protocol available.\n",
    "    pickle.dump(average_voting_tree_clf, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Show all result in one table and save it for future purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.735175</td>\n",
       "      <td>0.668421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting_RandomForestClassifier</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.591195</td>\n",
       "      <td>0.736972</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.776112</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_AdaBoostClassifier</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.757412</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.738208</td>\n",
       "      <td>0.673684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Voting_XGBClassifier</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.742026</td>\n",
       "      <td>0.668421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.630303</td>\n",
       "      <td>0.737758</td>\n",
       "      <td>0.678947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Voting_CatBoostClassifier</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TreeModelsVotingClassifier</td>\n",
       "      <td>0.614458</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.610778</td>\n",
       "      <td>0.731357</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TreeModelsAveragingVotingClassifier</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>0.673684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  precision_score  recall_score  \\\n",
       "0               RandomForestClassifier         0.632911      0.595238   \n",
       "1        Voting_RandomForestClassifier         0.626667      0.559524   \n",
       "2                   AdaBoostClassifier         0.680000      0.607143   \n",
       "3            Voting_AdaBoostClassifier         0.690141      0.583333   \n",
       "4                        XGBClassifier         0.630952      0.630952   \n",
       "5                 Voting_XGBClassifier         0.629630      0.607143   \n",
       "6                   CatBoostClassifier         0.641975      0.619048   \n",
       "7            Voting_CatBoostClassifier         0.650000      0.619048   \n",
       "8           TreeModelsVotingClassifier         0.614458      0.607143   \n",
       "9  TreeModelsAveragingVotingClassifier         0.641026      0.595238   \n",
       "\n",
       "   f1_score  roc_auc_score  accuracy_score  \n",
       "0  0.613497       0.735175        0.668421  \n",
       "1  0.591195       0.736972        0.657895  \n",
       "2  0.641509       0.776112        0.700000  \n",
       "3  0.632258       0.757412        0.700000  \n",
       "4  0.630952       0.738208        0.673684  \n",
       "5  0.618182       0.742026        0.668421  \n",
       "6  0.630303       0.737758        0.678947  \n",
       "7  0.634146       0.745283        0.684211  \n",
       "8  0.610778       0.731357        0.657895  \n",
       "9  0.617284       0.733827        0.673684  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary of results \n",
    "results_dict = {'precision_score': precision_score, \n",
    "               'recall_score': recall_score, \n",
    "               'f1_score': f1_score,\n",
    "               'roc_auc_score' : roc_auc_score,\n",
    "               'accuracy_score' : accuracy_score}\n",
    "\n",
    "results_df = pd.DataFrame(data=results_dict)\n",
    "results_df.insert(loc=0, column='Model', value=models_name)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"./results_new/tree_models_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
