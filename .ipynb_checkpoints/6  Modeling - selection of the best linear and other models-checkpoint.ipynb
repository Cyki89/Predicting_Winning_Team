{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6  Modeling - selection of the best linear and other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Purpose of the action </b> - checking accuracy of prediction on test set using different types of models:\n",
    "- LogisticRegression\n",
    "- LinearSVC\n",
    "- SVC with RBF\n",
    "- KNeighborsClassifier\n",
    "\n",
    "<b> </b>\n",
    "<b> Action plan </b>:\n",
    "- Test 20 diffrent models for each type\n",
    "- Use ParameterSampler to generate different models with random hyperparameters\n",
    "- Use training set for fitting model and use validation set for model evaluation \n",
    "- Select the best 5 models of each type and create one averaging model (Votingclassifier)\n",
    "- Retrain averaging model on all data (training and validation sets)\n",
    "- Create one large averaging model using the best one model of each type\n",
    "- Create another large averaging model from the previously created VotingClassifiers (each model contains the top 5 models of the same type)\n",
    "- Save this models for use in future\n",
    "- Compare prediction accuracy and other metrics on test set and save results for future purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Import nessesary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import pickle\n",
    "from modeling import make_voting_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Create empty lists for future results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = []\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "roc_auc_score = []\n",
    "models_name = []\n",
    "single_models = []\n",
    "voting_models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Perform ensembling for LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_lr.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_lr.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_test_set_lr.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression{'random_state': 4, 'max_iter': 1000, 'C': 0.001}\n",
      "Accuracy score on training set: 0.6593 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 2, 'max_iter': 1000, 'C': 1}\n",
      "Accuracy score on training set: 0.6779 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 10, 'max_iter': 1000, 'C': 0.001}\n",
      "Accuracy score on training set: 0.6593 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 0, 'max_iter': 1000, 'C': 0.001}\n",
      "Accuracy score on training set: 0.6593 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 1, 'max_iter': 1000, 'C': 10}\n",
      "Accuracy score on training set: 0.6795 | Accuracy score on validation set: 0.6636\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 3, 'max_iter': 1000, 'C': 10}\n",
      "Accuracy score on training set: 0.6795 | Accuracy score on validation set: 0.6636\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 0, 'max_iter': 1000, 'C': 1000}\n",
      "Accuracy score on training set: 0.6793 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 9, 'max_iter': 1000, 'C': 10}\n",
      "Accuracy score on training set: 0.6795 | Accuracy score on validation set: 0.6636\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 6, 'max_iter': 1000, 'C': 10}\n",
      "Accuracy score on training set: 0.6795 | Accuracy score on validation set: 0.6636\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 6, 'max_iter': 1000, 'C': 0.1}\n",
      "Accuracy score on training set: 0.6785 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 2, 'max_iter': 1000, 'C': 1000}\n",
      "Accuracy score on training set: 0.6793 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 8, 'max_iter': 1000, 'C': 1000}\n",
      "Accuracy score on training set: 0.6793 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 7, 'max_iter': 1000, 'C': 0.01}\n",
      "Accuracy score on training set: 0.6689 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 1, 'max_iter': 1000, 'C': 0.01}\n",
      "Accuracy score on training set: 0.6689 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 3, 'max_iter': 1000, 'C': 100}\n",
      "Accuracy score on training set: 0.6793 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 0, 'max_iter': 1000, 'C': 1}\n",
      "Accuracy score on training set: 0.6779 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 9, 'max_iter': 1000, 'C': 0.001}\n",
      "Accuracy score on training set: 0.6593 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 5, 'max_iter': 1000, 'C': 0.001}\n",
      "Accuracy score on training set: 0.6593 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 1, 'max_iter': 1000, 'C': 1}\n",
      "Accuracy score on training set: 0.6779 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 0, 'max_iter': 1000, 'C': 0.1}\n",
      "Accuracy score on training set: 0.6785 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n",
      "[\"LogisticRegression{'random_state': 0, 'max_iter': 1000, 'C': 0.1}\"\n",
      " \"LogisticRegression{'random_state': 6, 'max_iter': 1000, 'C': 0.1}\"\n",
      " \"LogisticRegression{'random_state': 3, 'max_iter': 1000, 'C': 100}\"\n",
      " \"LogisticRegression{'random_state': 1, 'max_iter': 1000, 'C': 0.01}\"\n",
      " \"LogisticRegression{'random_state': 7, 'max_iter': 1000, 'C': 0.01}\"]\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid={\n",
    "   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "   'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10],\n",
    "   'max_iter': [1000]\n",
    "}\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=LogisticRegression, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.5 Refit single and averaging models on the entire data set (training set+validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Voting_LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# merge training and validation sets\n",
    "X_all = np.concatenate([X_train, X_val], axis=0)\n",
    "y_all = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "# retrain models on all data\n",
    "clf.fit(X_all, y_all)\n",
    "voting_clf.fit(X_all, y_all)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'{clf.__class__.__name__}'\n",
    "voting_clf_name = f'Voting_{voting_clf.estimators_[0].__class__.__name__}'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Perform ensembling for LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_linearsvc.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_linearsvc.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_linearsvc.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 4, 'probability': True, 'kernel': 'linear', 'C': 0.001}\n",
      "Accuracy score on training set: 0.6525 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 2, 'probability': True, 'kernel': 'linear', 'C': 1}\n",
      "Accuracy score on training set: 0.6832 | Accuracy score on validation set: 0.6788\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 10, 'probability': True, 'kernel': 'linear', 'C': 0.001}\n",
      "Accuracy score on training set: 0.6525 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'kernel': 'linear', 'C': 0.001}\n",
      "Accuracy score on training set: 0.6525 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 1, 'probability': True, 'kernel': 'linear', 'C': 10}\n",
      "Accuracy score on training set: 0.6813 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 3, 'probability': True, 'kernel': 'linear', 'C': 10}\n",
      "Accuracy score on training set: 0.6813 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'kernel': 'linear', 'C': 1000}\n",
      "Accuracy score on training set: 0.6815 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 9, 'probability': True, 'kernel': 'linear', 'C': 10}\n",
      "Accuracy score on training set: 0.6813 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 6, 'probability': True, 'kernel': 'linear', 'C': 10}\n",
      "Accuracy score on training set: 0.6813 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 6, 'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "Accuracy score on training set: 0.6778 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 2, 'probability': True, 'kernel': 'linear', 'C': 1000}\n",
      "Accuracy score on training set: 0.6815 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 8, 'probability': True, 'kernel': 'linear', 'C': 1000}\n",
      "Accuracy score on training set: 0.6815 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 7, 'probability': True, 'kernel': 'linear', 'C': 0.01}\n",
      "Accuracy score on training set: 0.6609 | Accuracy score on validation set: 0.6485\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 1, 'probability': True, 'kernel': 'linear', 'C': 0.01}\n",
      "Accuracy score on training set: 0.6609 | Accuracy score on validation set: 0.6485\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 3, 'probability': True, 'kernel': 'linear', 'C': 100}\n",
      "Accuracy score on training set: 0.6815 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'kernel': 'linear', 'C': 1}\n",
      "Accuracy score on training set: 0.6832 | Accuracy score on validation set: 0.6788\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 9, 'probability': True, 'kernel': 'linear', 'C': 0.001}\n",
      "Accuracy score on training set: 0.6525 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 5, 'probability': True, 'kernel': 'linear', 'C': 0.001}\n",
      "Accuracy score on training set: 0.6525 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 1, 'probability': True, 'kernel': 'linear', 'C': 1}\n",
      "Accuracy score on training set: 0.6832 | Accuracy score on validation set: 0.6788\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "Accuracy score on training set: 0.6778 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "[\"SVC{'random_state': 1, 'probability': True, 'kernel': 'linear', 'C': 1}\"\n",
      " \"SVC{'random_state': 2, 'probability': True, 'kernel': 'linear', 'C': 1}\"\n",
      " \"SVC{'random_state': 0, 'probability': True, 'kernel': 'linear', 'C': 1}\"\n",
      " \"SVC{'random_state': 1, 'probability': True, 'kernel': 'linear', 'C': 10}\"\n",
      " \"SVC{'random_state': 3, 'probability': True, 'kernel': 'linear', 'C': 100}\"]\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid={\n",
    "   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "   'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10],\n",
    "   'kernel': ['linear'],\n",
    "   'probability' : [True],\n",
    "}\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=SVC, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=1, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.5 Refit single and averaging models on the entire data set (training set+validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Voting_LinearSVC\n"
     ]
    }
   ],
   "source": [
    "# merge training and validation sets\n",
    "X_all = np.concatenate([X_train, X_val], axis=0)\n",
    "y_all = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "# retrain models on all data\n",
    "clf.fit(X_all, y_all)\n",
    "voting_clf.fit(X_all, y_all)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'Linear{clf.__class__.__name__}'\n",
    "voting_clf_name = f'Voting_Linear{voting_clf.estimators_[0].__class__.__name__}'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Perform ensembling for SVC Classifier with RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_svc_rbf.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_svc_rbf.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_test_set_svc_rbf.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 1, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 100}\n",
      "Accuracy score on training set: 0.6582 | Accuracy score on validation set: 0.6364\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 2, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 100000}\n",
      "Accuracy score on training set: 0.681 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 8, 'probability': True, 'max_iter': 1000000, 'gamma': 0.01, 'C': 10000}\n",
      "Accuracy score on training set: 0.7576 | Accuracy score on validation set: 0.6152\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'max_iter': 1000000, 'gamma': 0.1, 'C': 10}\n",
      "Accuracy score on training set: 0.7375 | Accuracy score on validation set: 0.6424\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 6, 'probability': True, 'max_iter': 1000000, 'gamma': 0.1, 'C': 1000000}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.5909\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 8, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 100000}\n",
      "Accuracy score on training set: 0.681 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 9, 'probability': True, 'max_iter': 1000000, 'gamma': 0.001, 'C': 10}\n",
      "Accuracy score on training set: 0.6685 | Accuracy score on validation set: 0.6485\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 1000000}\n",
      "Accuracy score on training set: 0.6793 | Accuracy score on validation set: 0.6879\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 9, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 1000}\n",
      "Accuracy score on training set: 0.6682 | Accuracy score on validation set: 0.6485\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 6, 'probability': True, 'max_iter': 1000000, 'gamma': 0.01, 'C': 100}\n",
      "Accuracy score on training set: 0.6976 | Accuracy score on validation set: 0.6818\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 9, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-06, 'C': 10}\n",
      "Accuracy score on training set: 0.5278 | Accuracy score on validation set: 0.5152\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 2, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 10000}\n",
      "Accuracy score on training set: 0.6778 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 3, 'probability': True, 'max_iter': 1000000, 'gamma': 0.1, 'C': 100000}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.5909\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 3, 'probability': True, 'max_iter': 1000000, 'gamma': 0.001, 'C': 1000}\n",
      "Accuracy score on training set: 0.682 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 1, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-06, 'C': 1000000}\n",
      "Accuracy score on training set: 0.6781 | Accuracy score on validation set: 0.6606\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 3, 'probability': True, 'max_iter': 1000000, 'gamma': 0.01, 'C': 1000000}\n",
      "Accuracy score on training set: 0.5561 | Accuracy score on validation set: 0.5061\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 3, 'probability': True, 'max_iter': 1000000, 'gamma': 0.1, 'C': 100}\n",
      "Accuracy score on training set: 0.8194 | Accuracy score on validation set: 0.597\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 9, 'probability': True, 'max_iter': 1000000, 'gamma': 0.1, 'C': 1000000}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.5909\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 5, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-06, 'C': 10000}\n",
      "Accuracy score on training set: 0.668 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 5, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-06, 'C': 1000000}\n",
      "Accuracy score on training set: 0.6781 | Accuracy score on validation set: 0.6606\n",
      "--------------------------------------------------------------------------------\n",
      "[\"SVC{'random_state': 0, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 1000000}\"\n",
      " \"SVC{'random_state': 6, 'probability': True, 'max_iter': 1000000, 'gamma': 0.01, 'C': 100}\"\n",
      " \"SVC{'random_state': 2, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 100000}\"\n",
      " \"SVC{'random_state': 8, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 100000}\"\n",
      " \"SVC{'random_state': 2, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 10000}\"]\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid={\n",
    "   'C':  [10, 100, 1000, 10000, 100000, 1000000],\n",
    "   'gamma': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "   'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10],\n",
    "   'probability' : [True],\n",
    "   'max_iter': [1000000]\n",
    "}\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=SVC, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1e-05, kernel='rbf',\n",
       "    max_iter=1000000, probability=True, random_state=0, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.5 Refit single and averaging models on the entire data set (training set+validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_RBF Voting_SVC_RBF\n"
     ]
    }
   ],
   "source": [
    "# merge training and validation sets\n",
    "X_all = np.concatenate([X_train, X_val], axis=0)\n",
    "y_all = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "# retrain models on all data\n",
    "clf.fit(X_all, y_all)\n",
    "voting_clf.fit(X_all, y_all)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'{clf.__class__.__name__}_RBF'\n",
    "voting_clf_name = f'Voting_{voting_clf.estimators_[0].__class__.__name__}_RBF'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Perform ensembling for KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_knn.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_knn.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_test_set_knn.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier{'n_neighbors': 7, 'metric': 'cosine', 'leaf_size': 25}\n",
      "Accuracy score on training set: 0.7274 | Accuracy score on validation set: 0.6606\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 9, 'metric': 'manhattan', 'leaf_size': 35}\n",
      "Accuracy score on training set: 0.7177 | Accuracy score on validation set: 0.6636\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 15, 'metric': 'manhattan', 'leaf_size': 15}\n",
      "Accuracy score on training set: 0.7007 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 21, 'metric': 'cosine', 'leaf_size': 25}\n",
      "Accuracy score on training set: 0.6916 | Accuracy score on validation set: 0.6606\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 11, 'metric': 'cosine', 'leaf_size': 25}\n",
      "Accuracy score on training set: 0.7042 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 17, 'metric': 'manhattan', 'leaf_size': 35}\n",
      "Accuracy score on training set: 0.7024 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 11, 'metric': 'cosine', 'leaf_size': 20}\n",
      "Accuracy score on training set: 0.7042 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 13, 'metric': 'cosine', 'leaf_size': 15}\n",
      "Accuracy score on training set: 0.6976 | Accuracy score on validation set: 0.6545\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 11, 'metric': 'cosine', 'leaf_size': 15}\n",
      "Accuracy score on training set: 0.7042 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 15, 'metric': 'cosine', 'leaf_size': 25}\n",
      "Accuracy score on training set: 0.6946 | Accuracy score on validation set: 0.6636\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 9, 'metric': 'cosine', 'leaf_size': 35}\n",
      "Accuracy score on training set: 0.7126 | Accuracy score on validation set: 0.6606\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 21, 'metric': 'manhattan', 'leaf_size': 30}\n",
      "Accuracy score on training set: 0.6992 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 15, 'metric': 'manhattan', 'leaf_size': 35}\n",
      "Accuracy score on training set: 0.7007 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 9, 'metric': 'manhattan', 'leaf_size': 45}\n",
      "Accuracy score on training set: 0.7177 | Accuracy score on validation set: 0.6636\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 7, 'metric': 'manhattan', 'leaf_size': 15}\n",
      "Accuracy score on training set: 0.7365 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 11, 'metric': 'manhattan', 'leaf_size': 20}\n",
      "Accuracy score on training set: 0.7074 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 17, 'metric': 'manhattan', 'leaf_size': 30}\n",
      "Accuracy score on training set: 0.7024 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 7, 'metric': 'manhattan', 'leaf_size': 40}\n",
      "Accuracy score on training set: 0.7365 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 21, 'metric': 'manhattan', 'leaf_size': 45}\n",
      "Accuracy score on training set: 0.6992 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "KNeighborsClassifier{'n_neighbors': 13, 'metric': 'cosine', 'leaf_size': 40}\n",
      "Accuracy score on training set: 0.6976 | Accuracy score on validation set: 0.6545\n",
      "--------------------------------------------------------------------------------\n",
      "[\"KNeighborsClassifier{'n_neighbors': 15, 'metric': 'manhattan', 'leaf_size': 15}\"\n",
      " \"KNeighborsClassifier{'n_neighbors': 15, 'metric': 'manhattan', 'leaf_size': 35}\"\n",
      " \"KNeighborsClassifier{'n_neighbors': 21, 'metric': 'manhattan', 'leaf_size': 45}\"\n",
      " \"KNeighborsClassifier{'n_neighbors': 17, 'metric': 'manhattan', 'leaf_size': 30}\"\n",
      " \"KNeighborsClassifier{'n_neighbors': 21, 'metric': 'manhattan', 'leaf_size': 30}\"]\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid = {\n",
    "                  'n_neighbors' : [7, 9, 11, 13, 15, 17, 19, 21],\n",
    "                  'metric': ['manhattan', 'cosine'],\n",
    "                  'leaf_size' : [15, 20, 25, 30, 35, 40, 45]\n",
    "              }\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=KNeighborsClassifier, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=15, metric='manhattan',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=15, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.5 Refit single and averaging models on the entire data set (training set+validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier Voting_KNeighborsClassifier\n"
     ]
    }
   ],
   "source": [
    "# merge training and validation sets\n",
    "X_all = np.concatenate([X_train, X_val], axis=0)\n",
    "y_all = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "# retrain models on all data\n",
    "clf.fit(X_all, y_all)\n",
    "voting_clf.fit(X_all, y_all)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'{clf.__class__.__name__}'\n",
    "voting_clf_name = f'Voting_{voting_clf.estimators_[0].__class__.__name__}'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Merge single and voting classifiers in largest models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.1 Import data dedicated for this models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_categorical_train_set.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_categorical_validation_set.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_categorical_test_set.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])\n",
    "\n",
    "# merge training and validation sets\n",
    "X_all = np.concatenate([X_train, X_val], axis=0)\n",
    "y_all = np.concatenate([y_train, y_val], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.3 Create new largest voting models and fit them on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModelsVotingClassifier LinearModelsAveragingVotingClassifier\n"
     ]
    }
   ],
   "source": [
    "# create models\n",
    "\n",
    "# as base models using single classifier\n",
    "voting_linear_clf = VotingClassifier(estimators=single_models, voting='soft')\n",
    "# as base models using voting classifier\n",
    "average_voting_linear_clf = VotingClassifier(estimators=voting_models, voting='soft')\n",
    "\n",
    "# train models on all data\n",
    "voting_linear_clf.fit(X_all, y_all)\n",
    "average_voting_linear_clf.fit(X_all, y_all)\n",
    "\n",
    "# give models a name\n",
    "voting_linear_clf_name = 'LinearModelsVotingClassifier'\n",
    "average_voting_linear_clf_name = 'LinearModelsAveragingVotingClassifier'\n",
    "print(voting_linear_clf_name, average_voting_linear_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.4 Calculate metrics of predictions and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single voting classifier to the lists\n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_linear_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_linear_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_linear_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_linear_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_linear_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for averaging voting classifier to the lists \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , average_voting_linear_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , average_voting_linear_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , average_voting_linear_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , average_voting_linear_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , average_voting_linear_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(voting_linear_clf_name)\n",
    "models_name.append(average_voting_linear_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.5 Save models for future purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save single voting model using pickle library\n",
    "with open(f'./models/{voting_linear_clf_name}.pickle', 'wb') as f:\n",
    "    # pickle the 'models'using the highest protocol available.\n",
    "    pickle.dump(voting_linear_clf, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# save averaging voting model using pickle library\n",
    "with open(f'./models/{average_voting_linear_clf_name}.pickle', 'wb') as f:\n",
    "    # pickle the 'models'using the highest protocol available.\n",
    "    pickle.dump(average_voting_linear_clf, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 Show all result in one table and save it for future purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.713612</td>\n",
       "      <td>0.663158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting_LogisticRegression</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.705863</td>\n",
       "      <td>0.652632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.707483</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.677524</td>\n",
       "      <td>0.749449</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LinearSVC</td>\n",
       "      <td>0.697987</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.673139</td>\n",
       "      <td>0.749779</td>\n",
       "      <td>0.693939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC_RBF</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.663158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Voting_SVC_RBF</td>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.670157</td>\n",
       "      <td>0.723832</td>\n",
       "      <td>0.668421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.676662</td>\n",
       "      <td>0.621053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Voting_KNeighborsClassifier</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.676831</td>\n",
       "      <td>0.621053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearModelsVotingClassifier</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.712601</td>\n",
       "      <td>0.652632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearModelsAveragingVotingClassifier</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.711815</td>\n",
       "      <td>0.652632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model  precision_score  recall_score  \\\n",
       "0                     LogisticRegression         0.608696      0.666667   \n",
       "1              Voting_LogisticRegression         0.600000      0.642857   \n",
       "2                              LinearSVC         0.707483      0.650000   \n",
       "3                       Voting_LinearSVC         0.697987      0.650000   \n",
       "4                                SVC_RBF         0.592593      0.761905   \n",
       "5                         Voting_SVC_RBF         0.598131      0.761905   \n",
       "6                   KNeighborsClassifier         0.568182      0.595238   \n",
       "7            Voting_KNeighborsClassifier         0.568182      0.595238   \n",
       "8           LinearModelsVotingClassifier         0.600000      0.642857   \n",
       "9  LinearModelsAveragingVotingClassifier         0.597826      0.654762   \n",
       "\n",
       "   f1_score  roc_auc_score  accuracy_score  \n",
       "0  0.636364       0.713612        0.663158  \n",
       "1  0.620690       0.705863        0.652632  \n",
       "2  0.677524       0.749449        0.700000  \n",
       "3  0.673139       0.749779        0.693939  \n",
       "4  0.666667       0.732143        0.663158  \n",
       "5  0.670157       0.723832        0.668421  \n",
       "6  0.581395       0.676662        0.621053  \n",
       "7  0.581395       0.676831        0.621053  \n",
       "8  0.620690       0.712601        0.652632  \n",
       "9  0.625000       0.711815        0.652632  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary of results \n",
    "results_dict = {'precision_score': precision_score, \n",
    "               'recall_score': recall_score, \n",
    "               'f1_score': f1_score,\n",
    "               'roc_auc_score' : roc_auc_score,\n",
    "               'accuracy_score' : accuracy_score}\n",
    "\n",
    "results_df = pd.DataFrame(data=results_dict)\n",
    "results_df.insert(loc=0, column='Model', value=models_name)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results_df.to_csv(\"./results/linear_models_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
