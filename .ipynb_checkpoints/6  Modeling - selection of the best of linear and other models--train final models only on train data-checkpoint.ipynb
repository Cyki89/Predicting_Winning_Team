{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6  Modeling - selection of the best of linear and other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Purpose of the action </b> - checking accuracy of prediction on test set using different types of models:\n",
    "- LogisticRegression\n",
    "- LinearSVC\n",
    "- SVC with RBF\n",
    "- KNeighborsClassifier\n",
    "\n",
    "<b> </b>\n",
    "<b> Action plan </b>:\n",
    "- Test 20 diffrent models for each type\n",
    "- Use ParameterSampler to generate different models with random hyperparameters\n",
    "- Use training set for fitting model and use validation set for model evaluation \n",
    "- Select the best 5 models of each type and create one averaging model (Votingclassifier)\n",
    "- Create one large averaging model using the best one model of each type\n",
    "- Create another large averaging model from the previously created VotingClassifiers (each model contains the top 5 models of the same type)\n",
    "- Save this models for use in future\n",
    "- Compare prediction accuracy and other metrics on test set and save results for future purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Import nessesary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import pickle\n",
    "from modeling import make_voting_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Create empty lists for future results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = []\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "roc_auc_score = []\n",
    "models_name = []\n",
    "single_models = []\n",
    "voting_models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Perform ensembling for LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_lr.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_lr.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_test_set_lr.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression{'random_state': 4, 'max_iter': 1000, 'C': 0.001}\n",
      "Accuracy score on training set: 0.6593 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 2, 'max_iter': 1000, 'C': 1}\n",
      "Accuracy score on training set: 0.6779 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 10, 'max_iter': 1000, 'C': 0.001}\n",
      "Accuracy score on training set: 0.6593 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 0, 'max_iter': 1000, 'C': 0.001}\n",
      "Accuracy score on training set: 0.6593 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 1, 'max_iter': 1000, 'C': 10}\n",
      "Accuracy score on training set: 0.6795 | Accuracy score on validation set: 0.6636\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 3, 'max_iter': 1000, 'C': 10}\n",
      "Accuracy score on training set: 0.6795 | Accuracy score on validation set: 0.6636\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 0, 'max_iter': 1000, 'C': 1000}\n",
      "Accuracy score on training set: 0.6793 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 9, 'max_iter': 1000, 'C': 10}\n",
      "Accuracy score on training set: 0.6795 | Accuracy score on validation set: 0.6636\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 6, 'max_iter': 1000, 'C': 10}\n",
      "Accuracy score on training set: 0.6795 | Accuracy score on validation set: 0.6636\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 6, 'max_iter': 1000, 'C': 0.1}\n",
      "Accuracy score on training set: 0.6785 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 2, 'max_iter': 1000, 'C': 1000}\n",
      "Accuracy score on training set: 0.6793 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 8, 'max_iter': 1000, 'C': 1000}\n",
      "Accuracy score on training set: 0.6793 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 7, 'max_iter': 1000, 'C': 0.01}\n",
      "Accuracy score on training set: 0.6689 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 1, 'max_iter': 1000, 'C': 0.01}\n",
      "Accuracy score on training set: 0.6689 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 3, 'max_iter': 1000, 'C': 100}\n",
      "Accuracy score on training set: 0.6793 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 0, 'max_iter': 1000, 'C': 1}\n",
      "Accuracy score on training set: 0.6779 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 9, 'max_iter': 1000, 'C': 0.001}\n",
      "Accuracy score on training set: 0.6593 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 5, 'max_iter': 1000, 'C': 0.001}\n",
      "Accuracy score on training set: 0.6593 | Accuracy score on validation set: 0.6515\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 1, 'max_iter': 1000, 'C': 1}\n",
      "Accuracy score on training set: 0.6779 | Accuracy score on validation set: 0.6576\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression{'random_state': 0, 'max_iter': 1000, 'C': 0.1}\n",
      "Accuracy score on training set: 0.6785 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n",
      "[\"LogisticRegression{'random_state': 0, 'max_iter': 1000, 'C': 0.1}\"\n",
      " \"LogisticRegression{'random_state': 6, 'max_iter': 1000, 'C': 0.1}\"\n",
      " \"LogisticRegression{'random_state': 3, 'max_iter': 1000, 'C': 100}\"\n",
      " \"LogisticRegression{'random_state': 1, 'max_iter': 1000, 'C': 0.01}\"\n",
      " \"LogisticRegression{'random_state': 7, 'max_iter': 1000, 'C': 0.01}\"]\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid={\n",
    "   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "   'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10],\n",
    "   'max_iter': [1000]\n",
    "}\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=LogisticRegression, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.5 Fit averaging model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Voting_LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# train averaging model on training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'{clf.__class__.__name__}'\n",
    "voting_clf_name = f'Voting_{voting_clf.estimators_[0].__class__.__name__}'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Perform ensembling for LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_linearsvc.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_linearsvc.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_linearsvc.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 4, 'probability': True, 'kernel': 'linear', 'C': 0.001}\n",
      "Accuracy score on training set: 0.6525 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 2, 'probability': True, 'kernel': 'linear', 'C': 1}\n",
      "Accuracy score on training set: 0.6832 | Accuracy score on validation set: 0.6788\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 10, 'probability': True, 'kernel': 'linear', 'C': 0.001}\n",
      "Accuracy score on training set: 0.6525 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'kernel': 'linear', 'C': 0.001}\n",
      "Accuracy score on training set: 0.6525 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 1, 'probability': True, 'kernel': 'linear', 'C': 10}\n",
      "Accuracy score on training set: 0.6813 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 3, 'probability': True, 'kernel': 'linear', 'C': 10}\n",
      "Accuracy score on training set: 0.6813 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'kernel': 'linear', 'C': 1000}\n",
      "Accuracy score on training set: 0.6815 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 9, 'probability': True, 'kernel': 'linear', 'C': 10}\n",
      "Accuracy score on training set: 0.6813 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 6, 'probability': True, 'kernel': 'linear', 'C': 10}\n",
      "Accuracy score on training set: 0.6813 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 6, 'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "Accuracy score on training set: 0.6778 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 2, 'probability': True, 'kernel': 'linear', 'C': 1000}\n",
      "Accuracy score on training set: 0.6815 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 8, 'probability': True, 'kernel': 'linear', 'C': 1000}\n",
      "Accuracy score on training set: 0.6815 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 7, 'probability': True, 'kernel': 'linear', 'C': 0.01}\n",
      "Accuracy score on training set: 0.6609 | Accuracy score on validation set: 0.6485\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 1, 'probability': True, 'kernel': 'linear', 'C': 0.01}\n",
      "Accuracy score on training set: 0.6609 | Accuracy score on validation set: 0.6485\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 3, 'probability': True, 'kernel': 'linear', 'C': 100}\n",
      "Accuracy score on training set: 0.6815 | Accuracy score on validation set: 0.6758\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'kernel': 'linear', 'C': 1}\n",
      "Accuracy score on training set: 0.6832 | Accuracy score on validation set: 0.6788\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 9, 'probability': True, 'kernel': 'linear', 'C': 0.001}\n",
      "Accuracy score on training set: 0.6525 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 5, 'probability': True, 'kernel': 'linear', 'C': 0.001}\n",
      "Accuracy score on training set: 0.6525 | Accuracy score on validation set: 0.6455\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 1, 'probability': True, 'kernel': 'linear', 'C': 1}\n",
      "Accuracy score on training set: 0.6832 | Accuracy score on validation set: 0.6788\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "Accuracy score on training set: 0.6778 | Accuracy score on validation set: 0.6727\n",
      "--------------------------------------------------------------------------------\n",
      "[\"SVC{'random_state': 1, 'probability': True, 'kernel': 'linear', 'C': 1}\"\n",
      " \"SVC{'random_state': 2, 'probability': True, 'kernel': 'linear', 'C': 1}\"\n",
      " \"SVC{'random_state': 0, 'probability': True, 'kernel': 'linear', 'C': 1}\"\n",
      " \"SVC{'random_state': 1, 'probability': True, 'kernel': 'linear', 'C': 10}\"\n",
      " \"SVC{'random_state': 3, 'probability': True, 'kernel': 'linear', 'C': 100}\"]\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid={\n",
    "   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "   'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10],\n",
    "   'kernel': ['linear'],\n",
    "   'probability' : [True],\n",
    "}\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=SVC, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=1, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.5 Fit averaging model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Voting_LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# train averaging model on training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'{clf.__class__.__name__}'\n",
    "voting_clf_name = f'Voting_{voting_clf.estimators_[0].__class__.__name__}'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Perform ensembling for SVC Classifier with RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_svc_rbf.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_svc_rbf.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_test_set_svc_rbf.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 1, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 100}\n",
      "Accuracy score on training set: 0.6582 | Accuracy score on validation set: 0.6364\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 2, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 100000}\n",
      "Accuracy score on training set: 0.681 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 8, 'probability': True, 'max_iter': 1000000, 'gamma': 0.01, 'C': 10000}\n",
      "Accuracy score on training set: 0.7576 | Accuracy score on validation set: 0.6152\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'max_iter': 1000000, 'gamma': 0.1, 'C': 10}\n",
      "Accuracy score on training set: 0.7375 | Accuracy score on validation set: 0.6424\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 6, 'probability': True, 'max_iter': 1000000, 'gamma': 0.1, 'C': 1000000}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.5909\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 8, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 100000}\n",
      "Accuracy score on training set: 0.681 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 9, 'probability': True, 'max_iter': 1000000, 'gamma': 0.001, 'C': 10}\n",
      "Accuracy score on training set: 0.6685 | Accuracy score on validation set: 0.6485\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 0, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 1000000}\n",
      "Accuracy score on training set: 0.6793 | Accuracy score on validation set: 0.6879\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 9, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 1000}\n",
      "Accuracy score on training set: 0.6682 | Accuracy score on validation set: 0.6485\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 6, 'probability': True, 'max_iter': 1000000, 'gamma': 0.01, 'C': 100}\n",
      "Accuracy score on training set: 0.6976 | Accuracy score on validation set: 0.6818\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 9, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-06, 'C': 10}\n",
      "Accuracy score on training set: 0.5278 | Accuracy score on validation set: 0.5152\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 2, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-05, 'C': 10000}\n",
      "Accuracy score on training set: 0.6778 | Accuracy score on validation set: 0.6697\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 3, 'probability': True, 'max_iter': 1000000, 'gamma': 0.1, 'C': 100000}\n",
      "Accuracy score on training set: 1.0 | Accuracy score on validation set: 0.5909\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 3, 'probability': True, 'max_iter': 1000000, 'gamma': 0.001, 'C': 1000}\n",
      "Accuracy score on training set: 0.682 | Accuracy score on validation set: 0.6667\n",
      "--------------------------------------------------------------------------------\n",
      "SVC{'random_state': 1, 'probability': True, 'max_iter': 1000000, 'gamma': 1e-06, 'C': 1000000}\n",
      "Accuracy score on training set: 0.6781 | Accuracy score on validation set: 0.6606\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC{'random_state': 3, 'probability': True, 'max_iter': 1000000, 'gamma': 0.01, 'C': 1000000}\n",
      "Accuracy score on training set: 0.5561 | Accuracy score on validation set: 0.5061\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid={\n",
    "   'C':  [10, 100, 1000, 10000, 100000, 1000000],\n",
    "   'gamma': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "   'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10],\n",
    "   'probability' : [True],\n",
    "   'max_iter': [1000000]\n",
    "}\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=SVC, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.5 Fit averaging model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Voting_LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# train averaging model on training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'{clf.__class__.__name__}'\n",
    "voting_clf_name = f'Voting_{voting_clf.estimators_[0].__class__.__name__}'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Perform ensembling for KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.1 Import data dedicated for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_train_set_knn.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_validation_set_knn.csv\"), index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_test_set_knn.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.3 Perform averaging ensembling for this model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the top 5 models from 20 and create one model from them (Voting Classifier) using <b> ParameterSampler </b> for generating random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define params for random grid search\n",
    "params_grid = {\n",
    "                  'n_neighbors' : [7, 9, 11, 13, 15, 17, 19, 21],\n",
    "                  'metric': ['manhattan', 'cosine'],\n",
    "                  'leaf_size' : [15, 20, 25, 30, 35, 40, 45]\n",
    "              }\n",
    "\n",
    "# function build a voting classifier using n best models\n",
    "voting_clf = make_voting_classifier(estimator=KNeighborsClassifier, \n",
    "                                    params_grid=params_grid,\n",
    "                                    n_iter=20, \n",
    "                                    random_state=42,\n",
    "                                    X_train=X_train, \n",
    "                                    y_train=y_train, \n",
    "                                    X_val=X_val, \n",
    "                                    y_val=y_val, \n",
    "                                    verbose=1,\n",
    "                                    n_best_models=5, \n",
    "                                    voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "# look on the estimators of voting claffier\n",
    "print(voting_clf.estimators[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.4 Exctract the best single model from voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract single classifier\n",
    "clf = voting_clf.estimators_[0]\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.5 Fit averaging model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Voting_LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# train averaging model on training data\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# give models a name\n",
    "clf_name = f'{clf.__class__.__name__}'\n",
    "voting_clf_name = f'Voting_{voting_clf.estimators_[0].__class__.__name__}'\n",
    "print(clf_name, voting_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for voting classifier to the list  \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(clf_name)\n",
    "models_name.append(voting_clf_name)\n",
    "\n",
    "# add classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (clf_name, clf) )\n",
    "voting_models.append( (voting_clf_name, voting_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Merge single and voting classifiers in largest models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.1 Import data dedicated for this models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./preprocessed_data/processed_categorical_train_set.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_categorical_validation_set.csv\", index_col=0)\n",
    "test_set = pd.read_csv(\"./preprocessed_data/processed_categorical_test_set.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.2 Split datasets to feature set and labels set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "X_test, y_test = np.array(test_set.drop(columns='FTR')), np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.3 Create new largest voting models and fit them on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create models\n",
    "\n",
    "# as base models using single classifier\n",
    "voting_tree_clf = VotingClassifier(estimators=single_models, voting='soft')\n",
    "# as base models using voting classifier\n",
    "average_voting_tree_clf = VotingClassifier(estimators=voting_models, voting='soft')\n",
    "\n",
    "# train models on all data\n",
    "voting_tree_clf.fit(X_train, y_train)\n",
    "average_voting_tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# give models a name\n",
    "voting_linear_clf_name = 'LinearModelsVotingClassifier'\n",
    "average_voting_linear_clf_name = 'LinearModelsAveragingVotingClassifier'\n",
    "print(voting_linear_clf_name, average_voting_linear_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.4 Calculate metrics of predictions and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for single voting classifier to the lists\n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_linear_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_linear_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_linear_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_linear_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_linear_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# append metrics for averaging voting classifier to the lists \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , average_voting_linear_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , average_voting_linear_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , average_voting_linear_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , average_voting_linear_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , average_voting_linear_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(voting_linear_clf_name)\n",
    "models_name.append(average_voting_linear_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.5 Save models for future purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save single voting model using pickle library\n",
    "with open(f'./models_new/{voting_linear_clf_name}.pickle', 'wb') as f:\n",
    "    # pickle the 'models'using the highest protocol available.\n",
    "    pickle.dump(voting_linear_clf, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# save averaging voting model using pickle library\n",
    "with open(f'./models_new/{average_voting_linear_clf_name}.pickle', 'wb') as f:\n",
    "    # pickle the 'models'using the highest protocol available.\n",
    "    pickle.dump(average_voting_linear_clf, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 Show all result in one table and save it for future purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of results \n",
    "results_dict = {'precision_score': precision_score, \n",
    "               'recall_score': recall_score, \n",
    "               'f1_score': f1_score,\n",
    "               'roc_auc_score' : roc_auc_score,\n",
    "               'accuracy_score' : accuracy_score}\n",
    "\n",
    "results_df = pd.DataFrame(data=results_dict)\n",
    "results_df.insert(loc=0, column='Model', value=models_name)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results_df.to_csv(\"./results_new/linear_models_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
