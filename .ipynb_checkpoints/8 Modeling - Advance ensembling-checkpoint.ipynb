{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Modeling - Advance ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Purpose of the action </b> - create 3 advance machine learning models:\n",
    "- StackClassifier classifier consisting of:\n",
    "    - base models - best single models of each type from previous parts\n",
    "    - meta model - logistic regression with high regularization\n",
    "- VotingClassifier consisting of best single models from previous parts\n",
    "- VotingClassifier consisting of best five single models of each type from previous parts\n",
    "\n",
    "<b> </b>\n",
    "<b> Action plan </b>:\n",
    "- Create pipeline for each single model\n",
    "- Create StackClassifier \n",
    "- Create first VotingClassifier\n",
    "- Create pipeline for each averaging model\n",
    "- Create averaging Voting Classifier\n",
    "- Compare prediction accuracy and other metrics on the test set and save results for future purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Import nessesary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from preprocessing_pipelines import tree_preprocess_pipeline, linear_preprocess_pipeline\n",
    "from data_preprocessing import ImportantFeaturesSelector\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Import raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./preprocessed_data/train_set_stage2.csv', index_col=0)\n",
    "X_test = pd.read_csv('./preprocessed_data/test_set_stage2.csv', index_col=0) \n",
    "\n",
    "y_train = np.array(X_train['FTR'])\n",
    "y_test = np.array(X_test['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Import all previously prepared VotingClassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/LinearModelsVotingClassifier.pickle', 'rb') as f:\n",
    "    linear_voting_clf = pickle.load(f)\n",
    "    \n",
    "with open('./models/LinearModelsAveragingVotingClassifier.pickle', 'rb') as f:\n",
    "    linear_averaging_voting_clf = pickle.load(f) \n",
    "    \n",
    "with open('./models/TreeModelsVotingClassifier.pickle', 'rb') as f:\n",
    "    tree_voting_clf = pickle.load(f) \n",
    "\n",
    "with open('./models/TreeModelsAveragingVotingClassifier.pickle', 'rb') as f:\n",
    "    tree_averaging_voting_clf = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Extract models from VotingClassifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4.1 Extract best single models from VotingClassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1e-05, kernel='rbf',\n",
       "    max_iter=10000, probability=True, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract best tree-based estimators\n",
    "clf_rf, clf_ada, clf_xgb, clf_cat = tree_voting_clf.estimators\n",
    "\n",
    "# extract best linear estimators\n",
    "clf_lr, clf_svc, clf_rbf, clf_knn = linear_voting_clf.estimators\n",
    "\n",
    "# set max iteration for svc with linear and rbf kernels to save timie during training\n",
    "clf_svc[1].set_params(max_iter=10000)\n",
    "clf_rbf[1].set_params(max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4.2 Extract best averaging models from AveragingVotingClassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1e-05, kernel='rbf',\n",
       "    max_iter=10000, probability=True, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract best averaging tree-based estimators\n",
    "vot_clf_rf, vot_clf_ada, vot_clf_xgb, vot_clf_cat = tree_averaging_voting_clf.estimators\n",
    "\n",
    "# extract best averaging linear estimators\n",
    "vot_clf_lr, vot_clf_svc, vot_clf_rbf, vot_clf_knn = linear_averaging_voting_clf.estimators\n",
    "\n",
    "# # set max iteration for svc with linear and rbf kernels to save timie during training\n",
    "for i in range(5):\n",
    "    vot_clf_svc[1].estimators[i][1].set_params(max_iter=10000)\n",
    "    vot_clf_rbf[1].estimators[i][1].set_params(max_iter=10000)\n",
    "\n",
    "vot_clf_rbf[1].estimators[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Create empty list for future results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = []\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "roc_auc_score = []\n",
    "models_name  = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 Create pipelines for each individual model of each type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to use cross-validation instead of time-based validation for StackingClassifier due to the small amount of data. I had to prepare a full pre-processing pipeline for each model to avoid data leaks between folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.1 Create pipelines for tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImportantFeaturesSelector is from data_preprocessing.py\n",
    "# tree_preprocess_pipeline is from script preprocessing_pipelines.py \n",
    "\n",
    "# pipeline for RandomForestClassifier\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocess_pipeline', tree_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(clf_rf[1]) ),\n",
    "    (clf_rf)\n",
    "])\n",
    "\n",
    "# pipeline for XGBClassifier\n",
    "pipe_xgb = Pipeline([\n",
    "    ('preprocess_pipeline', tree_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(clf_xgb[1]) ),\n",
    "    (clf_xgb)\n",
    "])\n",
    "\n",
    "# pipeline for AdaBoostClassifier\n",
    "pipe_ada = Pipeline([\n",
    "    ('preprocess_pipeline', tree_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(clf_ada[1]) ),\n",
    "    (clf_ada)\n",
    "])\n",
    "\n",
    "# pipeline for CatBoostClassifier\n",
    "pipe_cat = Pipeline([\n",
    "    ('preprocess_pipeline', tree_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(clf_cat[1]) ),\n",
    "    (clf_cat)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.2 Create pipelines for linears models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImportantFeaturesSelector is from data_preprocessing.py\n",
    "# linear_preprocess_pipeline is from script preprocessing_pipelines.py \n",
    "\n",
    "# pipeline for Linear SVC\n",
    "pipe_svc = Pipeline([\n",
    "    ('preprocess_pipeline', linear_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(clf_svc[1]) ),\n",
    "    (clf_svc)\n",
    "])\n",
    "\n",
    "# pipeline for LogisticRegression\n",
    "pipe_lr = Pipeline([\n",
    "    ('preprocess_pipeline', linear_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(clf_lr[1]) ),\n",
    "    (clf_lr)\n",
    "])\n",
    "\n",
    "# pipeline for KNeighborsClassifier\n",
    "pipe_knn = Pipeline([\n",
    "    ('preprocess_pipeline', linear_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(clf_knn[1]) ),\n",
    "    (clf_knn)\n",
    "])\n",
    "\n",
    "# pipeline for SVC with rbf\n",
    "pipe_rbf = Pipeline([\n",
    "    ('preprocess_pipeline', linear_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(clf_rbf[1]) ),\n",
    "    (clf_rbf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.3 Create pipelines for averaging tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImportantFeaturesSelector is from data_preprocessing.py\n",
    "# tree_preprocess_pipeline is from script preprocessing_pipelines.py \n",
    "\n",
    "# pipeline for Voting RandomForestClassifier\n",
    "vot_pipe_rf = Pipeline([\n",
    "    ('preprocess_pipeline', tree_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(vot_clf_rf[1].estimators[0][1]) ),\n",
    "    (vot_clf_rf)\n",
    "])\n",
    "\n",
    "# pipeline for Voting XGBClassifier\n",
    "vot_pipe_xgb = Pipeline([\n",
    "    ('preprocess_pipeline', tree_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(vot_clf_xgb[1].estimators[0][1]) ),\n",
    "    (vot_clf_xgb)\n",
    "])\n",
    "\n",
    "# pipeline for Voting AdaBoostClassifier\n",
    "vot_pipe_ada = Pipeline([\n",
    "    ('preprocess_pipeline', tree_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(vot_clf_ada[1].estimators[0][1]) ),\n",
    "    (vot_clf_ada)\n",
    "])\n",
    "\n",
    "# pipeline for Voting CatBoostClassifier\n",
    "vot_pipe_cat = Pipeline([\n",
    "    ('preprocess_pipeline', tree_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(vot_clf_cat[1].estimators[0][1]) ),\n",
    "    (vot_clf_cat)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.4 Create pipelines for averaging linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImportantFeaturesSelector is from data_preprocessing.py\n",
    "# linear_preprocess_pipeline is from script preprocessing_pipelines.py \n",
    "\n",
    "# pipeline for Voting Linear SVC\n",
    "vot_pipe_svc = Pipeline([\n",
    "    ('preprocess_pipeline', linear_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(vot_clf_svc[1].estimators[0][1]) ),\n",
    "    (vot_clf_svc)\n",
    "])\n",
    "\n",
    "# pipeline for Voting LogisticRegression\n",
    "vot_pipe_lr = Pipeline([\n",
    "    ('preprocess_pipeline', linear_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(vot_clf_lr[1].estimators[0][1]) ),\n",
    "    (vot_clf_lr)\n",
    "])\n",
    "\n",
    "# pipeline for Voting KNeighborsClassifier\n",
    "vot_pipe_knn = Pipeline([\n",
    "    ('preprocess_pipeline', linear_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(vot_clf_knn[1].estimators[0][1]) ),\n",
    "    (vot_clf_knn)\n",
    "])\n",
    "\n",
    "# pipeline for Voting SVC with rbf\n",
    "vot_pipe_rbf = Pipeline([\n",
    "    ('preprocess_pipeline', linear_preprocess_pipeline),\n",
    "    ('feature_seletion', ImportantFeaturesSelector(vot_clf_rbf[1].estimators[0][1]) ),\n",
    "    (vot_clf_rbf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 Create StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.1 Initialize and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_clf = StackingClassifier(estimators=[('svc', pipe_svc), \n",
    "                                           ('lr', pipe_lr), \n",
    "                                           ('knn', pipe_knn), \n",
    "                                           ('rbf', pipe_rbf),\n",
    "                                           ('rf', pipe_rf), \n",
    "                                           ('xgb', pipe_xgb), \n",
    "                                           ('ada', pipe_ada), \n",
    "                                           ('cat', pipe_cat)],\n",
    "                                final_estimator = LogisticRegression(C=1),\n",
    "                                cv=5,\n",
    "                                n_jobs=1,\n",
    "                                verbose=10)\n",
    "\n",
    "stack_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.2 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StackingClassifier'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give model a name\n",
    "model_name = f'{stack_clf.__class__.__name__}'\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , stack_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , stack_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , stack_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , stack_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , stack_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8 Create VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.8.1 Initialize and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('svc', pipe_svc), \n",
    "                                           ('lr', pipe_lr), \n",
    "                                           ('knn', pipe_knn), \n",
    "                                           ('rbf', pipe_rbf),\n",
    "                                           ('rf', pipe_rf), \n",
    "                                           ('xgb', pipe_xgb), \n",
    "                                           ('ada', pipe_ada), \n",
    "                                           ('cat', pipe_cat)],\n",
    "                            voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.8.2 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AllModelsVotingClassifier'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give model a name\n",
    "model_name = f'AllModels{voting_clf.__class__.__name__}'\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.9 Create averaging VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.9.1 Initialize and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_voting_clf = VotingClassifier(estimators=[('svc', vot_pipe_svc), \n",
    "                                                  ('lr', vot_pipe_lr), \n",
    "                                                  ('knn', vot_pipe_knn), \n",
    "                                                  ('rbf', vot_pipe_rbf),\n",
    "                                                  ('rf',  vot_pipe_rf), \n",
    "                                                  ('xgb', vot_pipe_xgb), \n",
    "                                                  ('ada', vot_pipe_ada), \n",
    "                                                  ('cat', vot_pipe_cat)],\n",
    "                                      voting='soft')\n",
    "average_voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.9.2 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AllModelsAveragingVotingClassifier'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give model a name\n",
    "model_name = f'AllModelsAveraging{voting_clf.__class__.__name__}'\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append metrics for classifier to the list \n",
    "accuracy_score.append(metrics.accuracy_score(y_test , average_voting_clf.predict(X_test)))  \n",
    "precision_score.append(metrics.precision_score(y_test , average_voting_clf.predict(X_test)))\n",
    "recall_score.append(metrics.recall_score(y_test , average_voting_clf.predict(X_test)))\n",
    "f1_score.append( metrics.f1_score(y_test , average_voting_clf.predict(X_test)))\n",
    "roc_auc_score.append(metrics.roc_auc_score(y_test , average_voting_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# add claffiers name to the list (needed for created table with results)\n",
    "models_name.append(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.10 Show all result in one table and save it for future purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackingClassifier</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.745732</td>\n",
       "      <td>0.694737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AllModelsVotingClassifier</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.731469</td>\n",
       "      <td>0.663158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AllModelsAveragingVotingClassifier</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.736860</td>\n",
       "      <td>0.673684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  precision_score  recall_score  \\\n",
       "0                  StackingClassifier         0.644444      0.690476   \n",
       "1           AllModelsVotingClassifier         0.611111      0.654762   \n",
       "2  AllModelsAveragingVotingClassifier         0.627907      0.642857   \n",
       "\n",
       "   f1_score  roc_auc_score  accuracy_score  \n",
       "0  0.666667       0.745732        0.694737  \n",
       "1  0.632184       0.731469        0.663158  \n",
       "2  0.635294       0.736860        0.673684  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary of results \n",
    "results_dict = {'precision_score': precision_score, \n",
    "               'recall_score': recall_score, \n",
    "               'f1_score': f1_score,\n",
    "               'roc_auc_score' : roc_auc_score,\n",
    "               'accuracy_score' : accuracy_score}\n",
    "\n",
    "results_df = pd.DataFrame(data=results_dict)\n",
    "results_df.insert(loc=0, column='Model', value=models_name)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"./results/advance_ensembling_models_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
