{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Modeling - selection of the best linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Purpose of the action </b> - checking accuracy of prediction on test set using different types of models:\n",
    "- LogisticRegression\n",
    "- LinearSVC\n",
    "- SVC with RBF\n",
    "- KNeighborsClassifier\n",
    "\n",
    "<b> </b>\n",
    "<b> Action plan </b>:\n",
    "- Test 20 diffrent models for each type\n",
    "- Use ParameterSampler to generate different models with random hyperparameters\n",
    "- Use training set for fitting model and use validation set for model evaluation \n",
    "- Select the best 5 models of each type and create one AveragingClassifier\n",
    "- Train the best base models(top 1) of each type model on all data (training and validation sets)\n",
    "- Do the same with AveragingClassifiers\n",
    "- Create one AveragingClassifier using the best one model of each type\n",
    "- Create LargeAveragingClassifier from the previously created AveragingClassifier (each model contains the top 5 models of the same type)\n",
    "- Save models for use in future\n",
    "- Compare prediction accuracy and other metrics on test set and save results for future purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Import nessesary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from modeling import Metrics, select_best_classifiers, show_best_models\n",
    "from classifiers import AveragingClassifier, LargeAveragingClassifier\n",
    "from preprocessing_pipelines import categorical_preprocess_pipeline, ImportantFeaturesSelector\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Import data sets dedicated for linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sets for selecting best models of each type\n",
    "train_set = pd.read_csv(\"./preprocessed_data/processed_categorical_train_set.csv\", index_col=0)\n",
    "validation_set = pd.read_csv(\"./preprocessed_data/processed_categorical_validation_set.csv\", index_col=0)\n",
    "\n",
    "# data sets for final fiting and prediction\n",
    "train_set_all = pd.read_csv('./preprocessed_data/train_set_stage2.csv', index_col=0)\n",
    "test_set = pd.read_csv('./preprocessed_data/test_set_stage2.csv', index_col=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Split datasets to feature and label sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature and label sets for selecting models\n",
    "X_train, y_train = np.array(train_set.drop(columns='FTR')), np.array(train_set['FTR'])\n",
    "X_val, y_val = np.array(validation_set.drop(columns='FTR')), np.array(validation_set['FTR'])\n",
    "\n",
    "# feature and label sets for final training and prediction\n",
    "X_train_all, y_train_all = train_set_all, np.array(train_set_all['FTR'])\n",
    "X_test, y_test = test_set, np.array(test_set['FTR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Create placeholders to hold prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder to hold prediction results\n",
    "prediction_metrics = Metrics()\n",
    "\n",
    "# lists to hold model objects\n",
    "single_models = []\n",
    "averaging_models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1  Select best models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best 5 models from 20 tested models using multiprocessing and <b> ParameterSampler </b> for generating random parameters. Use accuracy_score on validation set as metric for models evaluation.\n",
    "Feature selection is made in the pipeline inside function for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place: 1\n",
      "LogisticRegression{'solver': 'liblinear', 'random_state': 2, 'penalty': 'l1', 'max_iter': 1000, 'C': 0.1}\n",
      "Accuracy score on validation set: 0.6818\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 2\n",
      "LogisticRegression{'solver': 'liblinear', 'random_state': 1, 'penalty': 'l1', 'max_iter': 1000, 'C': 0.1}\n",
      "Accuracy score on validation set: 0.6727\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 3\n",
      "LogisticRegression{'solver': 'liblinear', 'random_state': 8, 'penalty': 'l1', 'max_iter': 1000, 'C': 0.1}\n",
      "Accuracy score on validation set: 0.6667\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 4\n",
      "LogisticRegression{'solver': 'liblinear', 'random_state': 0, 'penalty': 'l2', 'max_iter': 1000, 'C': 1000}\n",
      "Accuracy score on validation set: 0.6667\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 5\n",
      "LogisticRegression{'solver': 'liblinear', 'random_state': 7, 'penalty': 'l2', 'max_iter': 1000, 'C': 0.001}\n",
      "Accuracy score on validation set: 0.6636\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid={\n",
    "   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "   'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10],\n",
    "   'max_iter': [1000],\n",
    "   'penalty': ['l1', 'l2'],\n",
    "   'solver' : ['liblinear']\n",
    "}\n",
    "    \n",
    "# to safely run multiprocessing on Windows\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # function selecting best classifiers using multiprocessing\n",
    "    best_models, best_scoring = select_best_classifiers(estimator=LogisticRegression, \n",
    "                                                        params_grid=params_grid,\n",
    "                                                        n_iter=20, \n",
    "                                                        random_state=23,\n",
    "                                                        X_train=X_train, \n",
    "                                                        y_train=y_train, \n",
    "                                                        X_val=X_val, \n",
    "                                                        y_val=y_val, \n",
    "                                                        verbose=1,\n",
    "                                                        n_best_models=5)\n",
    "    # show best selected models\n",
    "    show_best_models(best_models, best_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2 Extract single models from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1, clf_2, clf_3, clf_4, clf_5 = best_models[:,1][0].steps[1][1], best_models[:,1][1].steps[1][1], \\\n",
    "                                    best_models[:,1][2].steps[1][1], best_models[:,1][3].steps[1][1], \\\n",
    "                                    best_models[:,1][4].steps[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3 Create compleated pipelines (with scaling, encoding and futures selection) for each individual classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all base preprocess pipeline and transformers come from module preprocessing_pipelines.py\n",
    "pipe_clf_1 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_1, 'basic') ),\n",
    "                        ('classification', clf_1)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_2 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_2, 'basic') ),\n",
    "                        ('classification', clf_2)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_3 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_3, 'basic') ),\n",
    "                        ('classification', clf_3)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_4 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_4, 'basic') ),\n",
    "                        ('classification', clf_4)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_5 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_5, 'basic') ),\n",
    "                        ('classification', clf_5)\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.4  Make AveragingClassifier from the best 5 selected models (pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_clf = AveragingClassifier(base_estimators=[pipe_clf_1,\n",
    "                                               pipe_clf_2,\n",
    "                                               pipe_clf_3,\n",
    "                                               pipe_clf_4,\n",
    "                                               pipe_clf_5],\n",
    "                              voting='soft')\n",
    "\n",
    "# print(avg_clf.base_estimators[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.5 Fit single and averaging models on the entire data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression AveragingLogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# to safely run multiprocessing on Windows\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # train model on all data\n",
    "    pipe_clf_1.fit(X_train_all, y_train_all)\n",
    "    avg_clf.fit(X_train_all, y_train_all)\n",
    "\n",
    "    # give models a name\n",
    "    clf_1_name = f'{clf_1.__class__.__name__}'\n",
    "    avg_clf_name = f'Averaging{clf_1.__class__.__name__}'\n",
    "    print(clf_1_name, avg_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add prediction metrics for single classifier to placeholder\n",
    "prediction_metrics.add_metrics(pipe_clf_1, clf_1_name, X_test, y_test)\n",
    "\n",
    "# add prediction metrics for averaging classifier to placeholder\n",
    "prediction_metrics.add_metrics(avg_clf, avg_clf_name, X_test, y_test)\n",
    "\n",
    "# add both classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (pipe_clf_1) )\n",
    "averaging_models.append( (avg_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.1 Select best models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best 5 models from 20 tested models using multiprocessing and <b> ParameterSampler </b> for generating random parameters. Use accuracy_score on validation set as metric for models evaluation.\n",
    "Feature selection is made in the pipeline inside function for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place: 1\n",
      "SVC{'random_state': 7, 'probability': True, 'max_iter': 100000, 'kernel': 'linear', 'C': 1}\n",
      "Accuracy score on validation set: 0.6727\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 2\n",
      "SVC{'random_state': 8, 'probability': True, 'max_iter': 100000, 'kernel': 'linear', 'C': 0.01}\n",
      "Accuracy score on validation set: 0.6667\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 3\n",
      "SVC{'random_state': 9, 'probability': True, 'max_iter': 100000, 'kernel': 'linear', 'C': 0.01}\n",
      "Accuracy score on validation set: 0.6667\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 4\n",
      "SVC{'random_state': 3, 'probability': True, 'max_iter': 100000, 'kernel': 'linear', 'C': 0.01}\n",
      "Accuracy score on validation set: 0.6606\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 5\n",
      "SVC{'random_state': 4, 'probability': True, 'max_iter': 100000, 'kernel': 'linear', 'C': 0.01}\n",
      "Accuracy score on validation set: 0.6576\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid={\n",
    "   'C': [0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "   'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10],\n",
    "   'max_iter': [100000],\n",
    "   'kernel': ['linear'],\n",
    "   'probability' : [True],\n",
    "} \n",
    "\n",
    "# to safely run multiprocessing on Windows\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # function selecting best classifiers using multiprocessing\n",
    "    best_models, best_scoring = select_best_classifiers(estimator=SVC, \n",
    "                                                        params_grid=params_grid,\n",
    "                                                        n_iter=20, \n",
    "                                                        random_state=23,\n",
    "                                                        X_train=X_train, \n",
    "                                                        y_train=y_train, \n",
    "                                                        X_val=X_val, \n",
    "                                                        y_val=y_val, \n",
    "                                                        verbose=1,\n",
    "                                                        n_best_models=5)\n",
    "    # show best selected models\n",
    "    show_best_models(best_models, best_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.2 Extract single models from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1, clf_2, clf_3, clf_4, clf_5 = best_models[:,1][0].steps[1][1], best_models[:,1][1].steps[1][1], \\\n",
    "                                    best_models[:,1][2].steps[1][1], best_models[:,1][3].steps[1][1], \\\n",
    "                                    best_models[:,1][4].steps[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.3 Create compleated pipelines (with scaling, encoding and futures selection) for each individual classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all base preprocess pipeline and transformers come from module preprocessing_pipelines.py\n",
    "pipe_clf_1 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_1, 'basic') ),\n",
    "                        ('classification', clf_1)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_2 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_2, 'basic') ),\n",
    "                        ('classification', clf_2)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_3 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_3, 'basic') ),\n",
    "                        ('classification', clf_3)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_4 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_4, 'basic') ),\n",
    "                        ('classification', clf_4)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_5 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_5, 'basic') ),\n",
    "                        ('classification', clf_5)\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.4  Make AveragingClassifier from the best 5 selected models (pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_clf = AveragingClassifier(base_estimators=[pipe_clf_1,\n",
    "                                               pipe_clf_2,\n",
    "                                               pipe_clf_3,\n",
    "                                               pipe_clf_4,\n",
    "                                               pipe_clf_5],\n",
    "                              voting='soft')\n",
    "\n",
    "# print(avg_clf.base_estimators[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.5 Fit single and averaging models on the entire data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\48509\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC AveragingLinearSVC\n"
     ]
    }
   ],
   "source": [
    "# to safely run multiprocessing on Windows\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # train model on all data\n",
    "    pipe_clf_1.fit(X_train_all, y_train_all)\n",
    "    avg_clf.fit(X_train_all, y_train_all)\n",
    "\n",
    "    # give models a name\n",
    "    clf_1_name = f'Linear{clf_1.__class__.__name__}'\n",
    "    avg_clf_name = f'AveragingLinear{clf_1.__class__.__name__}'\n",
    "    print(clf_1_name, avg_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add prediction metrics for single classifier to placeholder\n",
    "prediction_metrics.add_metrics(pipe_clf_1, clf_1_name, X_test, y_test)\n",
    "\n",
    "# add prediction metrics for averaging classifier to placeholder\n",
    "prediction_metrics.add_metrics(avg_clf, avg_clf_name, X_test, y_test)\n",
    "\n",
    "# add both classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (pipe_clf_1) )\n",
    "averaging_models.append( (avg_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 SVC with RBF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.1 Select best models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best 5 models from 20 tested models using multiprocessing and <b> ParameterSampler </b> for generating random parameters. Use accuracy_score on validation set as metric for models evaluation.\n",
    "Feature selection is made in the pipeline inside function for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place: 1\n",
      "SVC{'random_state': 3, 'probability': True, 'max_iter': 100000, 'gamma': 1e-05, 'C': 100}\n",
      "Accuracy score on validation set: 0.6727\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 2\n",
      "SVC{'random_state': 5, 'probability': True, 'max_iter': 100000, 'gamma': 0.0001, 'C': 1000}\n",
      "Accuracy score on validation set: 0.6697\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 3\n",
      "SVC{'random_state': 8, 'probability': True, 'max_iter': 100000, 'gamma': 1e-05, 'C': 100}\n",
      "Accuracy score on validation set: 0.6697\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 4\n",
      "SVC{'random_state': 0, 'probability': True, 'max_iter': 100000, 'gamma': 1e-06, 'C': 10000}\n",
      "Accuracy score on validation set: 0.6545\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 5\n",
      "SVC{'random_state': 5, 'probability': True, 'max_iter': 100000, 'gamma': 0.0001, 'C': 10000}\n",
      "Accuracy score on validation set: 0.6515\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid={\n",
    "   'C':  [100, 1000, 10000, 100000, 1000000],\n",
    "   'gamma': [0.000001, 0.00001, 0.0001, 0.001, 0.01],\n",
    "   'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9, 10],\n",
    "   'probability' : [True],\n",
    "   'max_iter': [100000]\n",
    "} \n",
    "\n",
    "# to safely run multiprocessing on Windows\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # function selecting best classifiers using multiprocessing\n",
    "    best_models, best_scoring = select_best_classifiers(estimator=SVC, \n",
    "                                                        params_grid=params_grid,\n",
    "                                                        n_iter=20, \n",
    "                                                        random_state=23,\n",
    "                                                        X_train=X_train, \n",
    "                                                        y_train=y_train, \n",
    "                                                        X_val=X_val, \n",
    "                                                        y_val=y_val, \n",
    "                                                        verbose=1,\n",
    "                                                        n_best_models=5)\n",
    "    # show best selected models\n",
    "    show_best_models(best_models, best_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.2 Extract single models from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1, clf_2, clf_3, clf_4, clf_5 = best_models[:,1][0].steps[1][1], best_models[:,1][1].steps[1][1], \\\n",
    "                                    best_models[:,1][2].steps[1][1], best_models[:,1][3].steps[1][1], \\\n",
    "                                    best_models[:,1][4].steps[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.3 Create compleated pipelines (with scaling, encoding and futures selection) for each individual classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all base preprocess pipeline and transformers come from module preprocessing_pipelines.py\n",
    "pipe_clf_1 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_1, 'basic') ),\n",
    "                        ('classification', clf_1)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_2 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_2, 'basic') ),\n",
    "                        ('classification', clf_2)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_3 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_3, 'basic') ),\n",
    "                        ('classification', clf_3)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_4 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_4, 'basic') ),\n",
    "                        ('classification', clf_4)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_5 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_5, 'basic') ),\n",
    "                        ('classification', clf_5)\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.4  Make AveragingClassifier from the best 5 selected models (pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_clf = AveragingClassifier(base_estimators=[pipe_clf_1,\n",
    "                                               pipe_clf_2,\n",
    "                                               pipe_clf_3,\n",
    "                                               pipe_clf_4,\n",
    "                                               pipe_clf_5],\n",
    "                              voting='soft')\n",
    "\n",
    "# print(avg_clf.base_estimators[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.5 Fit single and averaging models on the entire data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SvcRbf AveragingSvcRbf\n"
     ]
    }
   ],
   "source": [
    "# to safely run multiprocessing on Windows\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # train model on all data\n",
    "    pipe_clf_1.fit(X_train_all, y_train_all)\n",
    "    avg_clf.fit(X_train_all, y_train_all)\n",
    "\n",
    "    # give models a name\n",
    "    clf_1_name = 'SvcRbf'\n",
    "    avg_clf_name = 'AveragingSvcRbf'\n",
    "    print(clf_1_name, avg_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add prediction metrics for single classifier to placeholder\n",
    "prediction_metrics.add_metrics(pipe_clf_1, clf_1_name, X_test, y_test)\n",
    "\n",
    "# add prediction metrics for averaging classifier to placeholder\n",
    "prediction_metrics.add_metrics(avg_clf, avg_clf_name, X_test, y_test)\n",
    "\n",
    "# add both classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (pipe_clf_1) )\n",
    "averaging_models.append( (avg_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8.1 Select best models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best 5 models from 20 tested models using multiprocessing and <b> ParameterSampler </b> for generating random parameters. Use accuracy_score on validation set as metric for models evaluation.\n",
    "Feature selection is made in the pipeline inside function for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place: 1\n",
      "KNeighborsClassifier{'n_neighbors': 13, 'metric': 'manhattan', 'leaf_size': 40}\n",
      "Accuracy score on validation set: 0.6818\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 2\n",
      "KNeighborsClassifier{'n_neighbors': 11, 'metric': 'manhattan', 'leaf_size': 25}\n",
      "Accuracy score on validation set: 0.6788\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 3\n",
      "KNeighborsClassifier{'n_neighbors': 17, 'metric': 'manhattan', 'leaf_size': 15}\n",
      "Accuracy score on validation set: 0.6727\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 4\n",
      "KNeighborsClassifier{'n_neighbors': 19, 'metric': 'cosine', 'leaf_size': 20}\n",
      "Accuracy score on validation set: 0.6667\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Place: 5\n",
      "KNeighborsClassifier{'n_neighbors': 15, 'metric': 'cosine', 'leaf_size': 20}\n",
      "Accuracy score on validation set: 0.6667\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# define params for random grid search\n",
    "params_grid = {\n",
    "                  'n_neighbors' : [9, 11, 13, 15, 17, 19, 21],\n",
    "                  'metric': ['manhattan', 'cosine'],\n",
    "                  'leaf_size' : [15, 20, 25, 30, 35, 40, 45]\n",
    "              } \n",
    "\n",
    "# to safely run multiprocessing on Windows\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # function selecting best classifiers using multiprocessing\n",
    "    best_models, best_scoring = select_best_classifiers(estimator=KNeighborsClassifier, \n",
    "                                                        params_grid=params_grid,\n",
    "                                                        n_iter=20, \n",
    "                                                        random_state=23,\n",
    "                                                        X_train=X_train, \n",
    "                                                        y_train=y_train, \n",
    "                                                        X_val=X_val, \n",
    "                                                        y_val=y_val, \n",
    "                                                        verbose=1,\n",
    "                                                        n_best_models=5)\n",
    "    # show best selected models\n",
    "    show_best_models(best_models, best_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8.2 Extract single models from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1, clf_2, clf_3, clf_4, clf_5 = best_models[:,1][0].steps[1][1], best_models[:,1][1].steps[1][1], \\\n",
    "                                    best_models[:,1][2].steps[1][1], best_models[:,1][3].steps[1][1], \\\n",
    "                                    best_models[:,1][4].steps[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8.3 Create compleated pipelines (with sclaing, encoding and futures selection) for each individual classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all base preprocess pipeline and transformers come from module preprocessing_pipelines.py\n",
    "pipe_clf_1 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_1, 'basic') ),\n",
    "                        ('classification', clf_1)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_2 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_2, 'basic') ),\n",
    "                        ('classification', clf_2)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_3 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_3, 'basic') ),\n",
    "                        ('classification', clf_3)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_4 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_4, 'basic') ),\n",
    "                        ('classification', clf_4)\n",
    "                      ])\n",
    "\n",
    "pipe_clf_5 = Pipeline([ ('preprocess_pipeline', categorical_preprocess_pipeline),\n",
    "                        ('feature_seletion', ImportantFeaturesSelector(clf_5, 'basic') ),\n",
    "                        ('classification', clf_5)\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8.4  Make AveragingClassifier from the best 5 selected models (pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_clf = AveragingClassifier(base_estimators=[pipe_clf_1,\n",
    "                                               pipe_clf_2,\n",
    "                                               pipe_clf_3,\n",
    "                                               pipe_clf_4,\n",
    "                                               pipe_clf_5],\n",
    "                              voting='soft')\n",
    "\n",
    "# print(avg_clf.base_estimators[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8.5 Fit single and averaging models on the entire data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier AveragingKNeighborsClassifier\n"
     ]
    }
   ],
   "source": [
    "# to safely run multiprocessing on Windows\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # train model on all data\n",
    "    pipe_clf_1.fit(X_train_all, y_train_all)\n",
    "    avg_clf.fit(X_train_all, y_train_all)\n",
    "\n",
    "    # give models a name\n",
    "    clf_1_name = f'{clf_1.__class__.__name__}'\n",
    "    avg_clf_name = f'Averaging{clf_1.__class__.__name__}'\n",
    "    print(clf_1_name, avg_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8.6 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add prediction metrics for single classifier to placeholder\n",
    "prediction_metrics.add_metrics(pipe_clf_1, clf_1_name, X_test, y_test)\n",
    "\n",
    "# add prediction metrics for averaging classifier to placeholder\n",
    "prediction_metrics.add_metrics(avg_clf, avg_clf_name, X_test, y_test)\n",
    "\n",
    "# add both classifiers to the lists (to create largest average classifiers)\n",
    "single_models.append( (pipe_clf_1) )\n",
    "averaging_models.append( (avg_clf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.9 Merge single and averaging models in largest averaging models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9.1 Create new largest averaging models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModelsAveragingClassifier LargeLinearModelsAveragingClassifier\n"
     ]
    }
   ],
   "source": [
    "# create models (all base model is already fitted)\n",
    "\n",
    "# as base models using single classifier\n",
    "average_lin_clf = AveragingClassifier(base_estimators=single_models, voting='soft')\n",
    "\n",
    "# as base models using averaging classifier\n",
    "large_average_lin_clf = LargeAveragingClassifier(base_estimators=averaging_models, voting='soft')\n",
    "\n",
    "# give models a name\n",
    "average_lin_clf_name = 'LinearModelsAveragingClassifier'\n",
    "large_average_lin_clf_name = 'LargeLinearModelsAveragingClassifier'\n",
    "print(average_lin_clf_name, large_average_lin_clf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9.2 Calculate metrics of prediction and add results to the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add prediction metrics for averaging classifier to placeholder\n",
    "prediction_metrics.add_metrics(average_lin_clf, average_lin_clf_name, X_test, y_test)\n",
    "\n",
    "# add prediction metrics for large averaging classifier to placeholder\n",
    "prediction_metrics.add_metrics(large_average_lin_clf, large_average_lin_clf_name, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9.3 Save models for future purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save single voting model using pickle library\n",
    "with open(f'./models/{average_lin_clf_name}.pickle', 'wb') as f:\n",
    "    # pickle the 'models'using the highest protocol available.\n",
    "    pickle.dump(average_lin_clf, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# save averaging voting model using pickle library\n",
    "with open(f'./models/{large_average_lin_clf_name}.pickle', 'wb') as f:\n",
    "    # pickle the 'models'using the highest protocol available.\n",
    "    pickle.dump(large_average_lin_clf, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10 Show all result in one table and save it for future purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.613861</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.670270</td>\n",
       "      <td>0.741914</td>\n",
       "      <td>0.678947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AveragingLogisticRegression</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.739780</td>\n",
       "      <td>0.663158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.691892</td>\n",
       "      <td>0.743261</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AveragingLinearSVC</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.735737</td>\n",
       "      <td>0.678947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SvcRbf</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.718553</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AveragingSvcRbf</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.737084</td>\n",
       "      <td>0.705263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.690757</td>\n",
       "      <td>0.652632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AveragingKNeighborsClassifier</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.703729</td>\n",
       "      <td>0.668421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearModelsAveragingClassifier</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.736074</td>\n",
       "      <td>0.668421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LargeLinearModelsAveragingClassifier</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.659341</td>\n",
       "      <td>0.734951</td>\n",
       "      <td>0.673684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model  precision_score  recall_score  \\\n",
       "0                    LogisticRegression         0.613861      0.738095   \n",
       "1           AveragingLogisticRegression         0.606383      0.678571   \n",
       "2                             LinearSVC         0.633663      0.761905   \n",
       "3                    AveragingLinearSVC         0.616162      0.726190   \n",
       "4                                SvcRbf         0.604396      0.654762   \n",
       "5                       AveragingSvcRbf         0.640000      0.761905   \n",
       "6                  KNeighborsClassifier         0.600000      0.642857   \n",
       "7         AveragingKNeighborsClassifier         0.615385      0.666667   \n",
       "8       LinearModelsAveragingClassifier         0.615385      0.666667   \n",
       "9  LargeLinearModelsAveragingClassifier         0.612245      0.714286   \n",
       "\n",
       "   f1_score  roc_auc_score  accuracy_score  \n",
       "0  0.670270       0.741914        0.678947  \n",
       "1  0.640449       0.739780        0.663158  \n",
       "2  0.691892       0.743261        0.700000  \n",
       "3  0.666667       0.735737        0.678947  \n",
       "4  0.628571       0.718553        0.657895  \n",
       "5  0.695652       0.737084        0.705263  \n",
       "6  0.620690       0.690757        0.652632  \n",
       "7  0.640000       0.703729        0.668421  \n",
       "8  0.640000       0.736074        0.668421  \n",
       "9  0.659341       0.734951        0.673684  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get prediction metric result lists from placeholder\n",
    "precision_score, recall_score, f1_score, roc_auc_score, accuracy_score = prediction_metrics.get_metrics()\n",
    "\n",
    "# get model names list from placeholder\n",
    "models_name = prediction_metrics.get_names()\n",
    "\n",
    "# create dictionary of results \n",
    "results_dict = {'precision_score': precision_score, \n",
    "               'recall_score': recall_score, \n",
    "               'f1_score': f1_score,\n",
    "               'roc_auc_score' : roc_auc_score,\n",
    "               'accuracy_score' : accuracy_score}\n",
    "\n",
    "results_df = pd.DataFrame(data=results_dict)\n",
    "results_df.insert(loc=0, column='Model', value=models_name)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"./results/linear_models_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
